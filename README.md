# National-cultural-memory-under-AI
 national cultural memory
import os
import tkinter as tk
import random
import time
import json
import requests
import shutil
import traceback
import threading
import pyaudio
import serial
import serial.tools.list_ports
from PIL import Image, ImageTk, ImageDraw, ImageFont
from datetime import datetime
import pytz
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
import numpy as np  # æ·»åŠ numpyå¯¼å…¥
import speech_recognition as sr

expected_char=''
# ===== ä¿®æ”¹æ­¥éª¤1: åœ¨å…¨å±€å˜é‡åŒºåŸŸæ·»åŠ ä¼šå‘˜é…ç½® =====
# åœ¨ä½ çš„ä»£ç ä¸­ï¼Œæ‰¾åˆ°è¿™äº›è¡Œï¼ˆå¤§çº¦åœ¨ç¬¬20-30è¡Œå·¦å³ï¼‰ï¼š

# ========== API Keys and URLs ==========
# Tripo 3D API for 3D model generation (Updated)
TRIPO_API_KEY = ""
TRIPO_BASE_URL = ""

# åœ¨ä¸Šé¢è¿™äº›è¡Œçš„åé¢æ·»åŠ ä»¥ä¸‹ä¼šå‘˜é…ç½®ï¼š
# ========== Tripo AI ä¼šå‘˜é…ç½® ==========
TRIPO_MEMBER_CONFIG = {
    "is_member": True,  # è®¾ç½®ä¸ºTrueå¯ç”¨ä¼šå‘˜ä¼˜åŒ–
    "member_benefits": {
        "priority_queue": True,  # ä¼˜å…ˆé˜Ÿåˆ—
        "faster_gpu": True,  # æ›´å¿«GPU
        "concurrent_tasks": 3,  # å¹¶å‘ä»»åŠ¡æ•°
        "reduced_throttling": True  # å‡å°‘é™æµ
    }
}


def get_expected_generation_time(model_version="v2.0", face_count=1000, is_member=True):
    """æ ¹æ®ä¼šå‘˜çŠ¶æ€å’Œæ¨¡å‹é…ç½®é¢„ä¼°ç”Ÿæˆæ—¶é—´"""

    # åŸºç¡€ç”Ÿæˆæ—¶é—´ï¼ˆå…è´¹ç”¨æˆ·ï¼‰
    base_times = {
        "v1.4": {"min": 45, "max": 90},  # v1.4: 45-90ç§’
        "v2.0": {"min": 60, "max": 120}  # v2.0: 60-120ç§’
    }

    base_time = base_times.get(model_version, base_times["v2.0"])

    if is_member:
        # ä¼šå‘˜åŠ é€Ÿå› å­
        speed_multipliers = {
            "priority_queue": 0.7,  # ä¼˜å…ˆé˜Ÿåˆ—å‡å°‘30%ç­‰å¾…
            "faster_gpu": 0.8,  # æ›´å¿«GPUå‡å°‘20%è®¡ç®—æ—¶é—´
            "reduced_throttling": 0.9  # å‡å°‘é™æµå‡å°‘10%å»¶è¿Ÿ
        }

        # è®¡ç®—ä¼šå‘˜åŠ é€Ÿåçš„æ—¶é—´
        accelerated_min = int(base_time["min"] * speed_multipliers["priority_queue"] * speed_multipliers["faster_gpu"])
        accelerated_max = int(base_time["max"] * speed_multipliers["priority_queue"] * speed_multipliers["faster_gpu"])

        return {
            "free_user": f"{base_time['min']}-{base_time['max']}ç§’",
            "member": f"{accelerated_min}-{accelerated_max}ç§’",
            "improvement": f"æå‡çº¦{int((1 - accelerated_max / base_time['max']) * 100)}%",
            "concurrent_tasks": TRIPO_MEMBER_CONFIG["member_benefits"]["concurrent_tasks"]
        }
    else:
        return {
            "free_user": f"{base_time['min']}-{base_time['max']}ç§’",
            "member": "æœªå¼€é€šä¼šå‘˜",
            "improvement": "æ— æå‡",
            "concurrent_tasks": 1
        }


def create_member_optimized_session():
    """åˆ›å»ºä¸ºä¼šå‘˜ä¼˜åŒ–çš„è¯·æ±‚ä¼šè¯"""
    session = create_requests_session()

    if TRIPO_MEMBER_CONFIG["is_member"]:
        # ä¼šå‘˜ä¸“å±è¯·æ±‚å¤´
        session.headers.update({
            "X-Priority": "high",
            "X-Member-Tier": "premium",
            "X-Concurrent-Enabled": "true"
        })

    return session


# Voskæ¨¡å‹è·¯å¾„é…ç½®
VOSK_MODEL_PATH = r"C:\111\vosk-model-cn-0.22"  # ä¸­æ–‡è¯­éŸ³è¯†åˆ«æ¨¡å‹è·¯å¾„
# åœ¨VOSK_MODEL_PATHåé¢æ·»åŠ 
SPEECH_CONFIG = {
    "use_google_speech": True,  # ä½¿ç”¨Googleè¯­éŸ³è¯†åˆ«ä½œä¸ºä¸»è¦æ–¹æ¡ˆ
    "use_vosk_fallback": True,  # Voskä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ
    "energy_threshold": 4000,   # æé«˜èƒ½é‡é˜ˆå€¼ï¼Œå‡å°‘è¯¯è¯†åˆ«
    "dynamic_energy_threshold": True,
    "pause_threshold": 0.8,
    "phrase_threshold": 0.3,
    "non_speaking_duration": 0.8,
    "timeout": 3,
    "phrase_timeout": 2,
}

# ========== Directory Configuration ==========
# Base directories
BASE_DIR = r"C:\111"
COMFYUI_DIR = r"C:\111\ComfyUI-aki\ComfyUI-aki-v1.6\ComfyUI"
IMAGE_DISPLAY_FOLDER = os.path.join(BASE_DIR, "æ–‡æœ¬è½¬å›¾ç‰‡")

# Output directories
VOICE_DIR = os.path.join(BASE_DIR, "è¯­éŸ³æµ‹è¯•A")
IMAGE_OUTPUT_DIR = os.path.join(COMFYUI_DIR, "output")  # Updated path
MODEL_OUTPUT_DIR = os.path.join(BASE_DIR, "3Dæ¨¡å‹è¾“å‡º")

# Create directories if they don't exist
for directory in [VOICE_DIR, IMAGE_OUTPUT_DIR, MODEL_OUTPUT_DIR, IMAGE_DISPLAY_FOLDER]:
    os.makedirs(directory, exist_ok=True)

# File paths
VOICE_TEXT_FILE = os.path.join(VOICE_DIR, "è¯­éŸ³æµ‹è¯•A.txt")

# ========== UI Configuration ==========
WINDOW_WIDTH = 1620
WINDOW_HEIGHT = 1920
SCROLL_SPEED = 1

# å›¾åƒæ˜¾ç¤ºä¼˜åŒ–é…ç½®
MAX_IMAGES_TOTAL = 50  # æœ€å¤§å›¾ç‰‡æ€»æ•°
IMAGE_LOAD_DELAY = 1
UI_UPDATE_INTERVAL = 50

# æ™ºèƒ½å¸ƒå±€é…ç½®è¡¨ - ç¡®ä¿å›¾ç‰‡å§‹ç»ˆå æ»¡UI
LAYOUT_TABLE = {
    1: {"rows": 1, "cols": 1},     # 1å¼ ï¼š1x1ï¼Œå æ»¡æ•´ä¸ªUI
    2: {"rows": 1, "cols": 2},     # 2å¼ ï¼š1x2
    3: {"rows": 1, "cols": 3},     # 3å¼ ï¼š1x3
    4: {"rows": 2, "cols": 2},     # 4å¼ ï¼š2x2
    5: {"rows": 1, "cols": 5},     # 5å¼ ï¼š1x5
    6: {"rows": 2, "cols": 3},     # 6å¼ ï¼š2x3
    9: {"rows": 3, "cols": 3},     # 9å¼ ï¼š3x3
    10: {"rows": 2, "cols": 5},    # 10å¼ ï¼š2x5
    12: {"rows": 3, "cols": 4},    # 12å¼ ï¼š3x4
    15: {"rows": 3, "cols": 5},    # 15å¼ ï¼š3x5ï¼Œæ­£å¥½
    16: {"rows": 4, "cols": 4},    # 16å¼ ï¼š4x4
    20: {"rows": 4, "cols": 5},    # 20å¼ ï¼š4x5
    25: {"rows": 5, "cols": 5},    # 25å¼ ï¼š5x5
    30: {"rows": 5, "cols": 6},    # 30å¼ ï¼š5x6
    36: {"rows": 6, "cols": 6},    # 36å¼ ï¼š6x6ï¼Œæ­£å¥½
    40: {"rows": 5, "cols": 8},    # 40å¼ ï¼š5x8
    50: {"rows": 5, "cols": 10},   # 50å¼ ï¼š5x10ï¼Œæœ€å¤§é…ç½®
}

# Set timezone to Beijing time
BEIJING_TZ = pytz.timezone("Asia/Shanghai")

# ========== Global Variables ==========
processing_queue = []
processing_lock = threading.Lock()
is_processing = False
# å›¾åƒä¸è¯­éŸ³æ–‡æœ¬çš„æ˜ å°„å…³ç³»
image_text_mapping = {}
# æ˜ å°„æ–‡ä»¶è·¯å¾„
MAPPING_FILE = os.path.join(BASE_DIR, "image_text_mapping.json")

# æ—‹é’®æ§åˆ¶å˜é‡
knob_control_active = False
current_angle = 0
rotation_models = ["bishe01", "bishe02", "bishe03"]  # æ—‹è½¬ç”Ÿæˆçš„æ¨¡å‹æ–‡ä»¶å


def save_image_mapping():
    """ä¿å­˜å›¾åƒæ–‡æœ¬æ˜ å°„åˆ°æ–‡ä»¶"""
    try:
        with open(MAPPING_FILE, 'w', encoding='utf-8') as f:
            json.dump(image_text_mapping, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"âŒ ä¿å­˜æ˜ å°„æ–‡ä»¶å¤±è´¥: {e}")


def load_image_mapping():
    """ä»æ–‡ä»¶åŠ è½½å›¾åƒæ–‡æœ¬æ˜ å°„"""
    global image_text_mapping
    try:
        if os.path.exists(MAPPING_FILE):
            with open(MAPPING_FILE, 'r', encoding='utf-8') as f:
                image_text_mapping = json.load(f)
            print(f"âœ… å·²åŠ è½½ {len(image_text_mapping)} ä¸ªå›¾åƒæ–‡æœ¬æ˜ å°„")
        else:
            image_text_mapping = {}
    except Exception as e:
        print(f"âŒ åŠ è½½æ˜ å°„æ–‡ä»¶å¤±è´¥: {e}")
        image_text_mapping = {}


def create_requests_session():
    """åˆ›å»ºå¸¦æœ‰ä»£ç†é…ç½®çš„requestsä¼šè¯"""
    session = requests.Session()
    # å°è¯•ç¦ç”¨ç³»ç»Ÿä»£ç†
    session.trust_env = False
    session.proxies = {
        'http': None,
        'https': None,
    }
    # è®¾ç½®ç¯å¢ƒå˜é‡ä»¥ç¦ç”¨ä»£ç†
    os.environ.pop('HTTP_PROXY', None)
    os.environ.pop('HTTPS_PROXY', None)
    os.environ.pop('http_proxy', None)
    os.environ.pop('https_proxy', None)
    return session


# ========== æ—‹é’®æ§åˆ¶ç³»ç»Ÿ ==========
class KnobControlSystem:
    """æ—‹é’®æ§åˆ¶ç³»ç»Ÿ - ç›‘å¬çœŸå®Arduinoç¡¬ä»¶"""

    def __init__(self):
        self.active = False
        self.current_angle = 0
        self.last_stable_angle = 0
        self.current_resolution = "medium"
        self.serial_connection = None
        self.serial_thread = None
        self.angle_buffer = []  # è§’åº¦ç¼“å†²åŒºï¼Œç”¨äºç¨³å®šæ€§å¤„ç†
        self.buffer_size = 5  # ç¼“å†²åŒºå¤§å°
        self.angle_threshold = 10  # è§’åº¦å˜åŒ–é˜ˆå€¼
        self.last_angle_change_time = 0
        self.debounce_delay = 2.0  # é˜²æŠ–å»¶è¿Ÿ2ç§’

    def initialize(self, port='COM13', baudrate=57600):
        """åˆå§‹åŒ–æ—‹é’®æ§åˆ¶ç³»ç»Ÿå¹¶è¿æ¥Arduino"""
        try:
            self.serial_connection = serial.Serial(port, baudrate, timeout=1)
            time.sleep(2)  # ç­‰å¾…Arduinoåˆå§‹åŒ–
            self.active = True

            print("ğŸ›ï¸ æ—‹é’®æ§åˆ¶ç³»ç»Ÿå·²åˆå§‹åŒ–")
            print(f"ğŸ”Œ å·²è¿æ¥Arduino Leonardoä¸²å£: {port}")
            print("ğŸ“‹ æ—‹é’®è§’åº¦æ˜ å°„:")
            print("   0åº¦ = bishe01 æ¨¡å‹ + 1080Ã—1080åˆ†è¾¨ç‡")
            print("   90åº¦ = bishe02 æ¨¡å‹ + 444Ã—444åˆ†è¾¨ç‡")
            print("   180åº¦ = bishe03 æ¨¡å‹ + 64Ã—64åˆ†è¾¨ç‡")
            print("ğŸ›ï¸ å¼€å§‹ç›‘å¬Leonardoç¡¬ä»¶æ—‹é’®...")

            # å¯åŠ¨ä¸²å£ç›‘å¬çº¿ç¨‹
            self.start_serial_listening()
            return True

        except Exception as e:
            print(f"âŒ Arduino Leonardoè¿æ¥å¤±è´¥: {e}")
            print("è¯·æ£€æŸ¥:")
            print("1. Arduino Leonardoæ˜¯å¦å·²è¿æ¥åˆ°COM13")
            print("2. ä¸²å£å·æ˜¯å¦æ­£ç¡® (åº”ä¸ºCOM13)")
            print("3. æ³¢ç‰¹ç‡æ˜¯å¦åŒ¹é… (57600)")
            print("4. Leonardoé©±åŠ¨æ˜¯å¦æ­£ç¡®å®‰è£…")
            return False

    def listen_serial_data(self):
        """ç›‘å¬ä¸²å£æ•°æ®"""
        print("ğŸ¯ å¼€å§‹ç›‘å¬ä¸²å£æ•°æ®...")
        print("ğŸ›ï¸ æ˜ å°„å…³ç³»: Bâ†’0Â°, Nâ†’90Â°, Mâ†’180Â°")

        # ç¡®ä¿åˆå§‹è§’åº¦ä¸º0
        self.current_angle = 0
        print(f"âš™ï¸ åˆå§‹è§’åº¦è®¾ç½®ä¸º: {self.current_angle}Â°")

        while self.active and self.serial_connection:
            try:
                if self.serial_connection.in_waiting > 0:
                    raw_data = self.serial_connection.read(self.serial_connection.in_waiting)

                    # æ·»åŠ åŸå§‹æ•°æ®è°ƒè¯•æ‰“å°
                    print(f"ğŸ“¦ åŸå§‹æ•°æ®: {raw_data}")

                    for byte in raw_data:
                        char = chr(byte).upper()
                        print(f"ğŸ” æ¥æ”¶åˆ°å­—ç¬¦: {char}")  # è°ƒè¯•æ‰€æœ‰å­—ç¬¦

                        if char in ['B', 'N', 'M']:
                            print(f"ğŸ¯ è¯†åˆ«åˆ°æœ‰æ•ˆæŒ‡ä»¤: {char}")
                            self.process_angle_input(char)
                            break

                time.sleep(0.01)

            except Exception as e:
                print(f"âŒ é”™è¯¯: {e}")
                time.sleep(0.01)

    def process_angle_input(self, char_input):
        """å¤„ç†è§’åº¦è¾“å…¥ - å¸¦è¯¦ç»†è°ƒè¯•ä¿¡æ¯"""
        # æ­£ç¡®çš„æ˜ å°„å…³ç³»
        angle_mapping = {
            'B': 0,  # B â†’ 0Â°
            'N': 90,  # N â†’ 90Â°
            'M': 180  # M â†’ 180Â°
        }

        # è°ƒè¯•ï¼šæ‰“å°å½“å‰æ˜ å°„è¡¨
        print(f"ğŸ—ºï¸ å½“å‰æ˜ å°„è¡¨: {angle_mapping}")

        if char_input in angle_mapping:
            new_angle = angle_mapping[char_input]
            print(f"ğŸ”§ æ˜ å°„ {char_input} â†’ {new_angle}Â°")
            self.update_angle(new_angle)
        else:
            print(f"âš ï¸ æ— æ•ˆå­—ç¬¦: {char_input}")

    def update_angle(self, new_angle):
        """æ›´æ–°è§’åº¦ - å¸¦è¯¦ç»†çŠ¶æ€æ£€æŸ¥"""
        # æ‰“å°å½“å‰çŠ¶æ€
        print(f"ğŸ“Š æ›´æ–°å‰çŠ¶æ€: å½“å‰è§’åº¦={self.current_angle}Â°, æ–°è§’åº¦={new_angle}Â°")

        if new_angle == self.current_angle:
            print("ğŸ”„ è§’åº¦æœªå˜åŒ–ï¼Œè·³è¿‡æ›´æ–°")
            return

        old_angle = self.current_angle
        print(old_angle)
        self.current_angle = new_angle
        print(self.current_angle)

        # è·å–åˆ†è¾¨ç‡ä¿¡æ¯
        resolution_info = self.get_resolution_by_angle(new_angle)

        print(f"ğŸ”„ è§’åº¦å˜åŒ–: {old_angle}Â° â†’ {self.current_angle}Â°")
        print(f"ğŸ–¥ï¸ åˆ†è¾¨ç‡åˆ‡æ¢: {resolution_info['width']}Ã—{resolution_info['height']}")

        self.generate_rotated_model()

    def get_resolution_by_angle(self, angle):
        if angle == 0:  # Bæ˜ å°„ä¸º 0Â°
            return {"mode": "high", "width": 1080, "height": 1080}  # ä¿®æ”¹ä¸º 1080Ã—1080
        elif angle == 180:  # Mæ˜ å°„ä¸º 90Â°
            return {"mode": "medium", "width": 444, "height": 444}  # ä¿æŒ 444Ã—444
        else:  # Næ˜ å°„ä¸º 180Â°
            return {"mode": "low", "width": 64, "height": 64}  # ä¿®æ”¹ä¸º 64Ã—64

    def generate_rotated_model(self):
        """æ ¹æ®å½“å‰è§’åº¦ç”Ÿæˆå¯¹åº”æ¨¡å‹"""
        try:
            # æ ¹æ®è§’åº¦é€‰æ‹©å¯¹åº”çš„æ¨¡å‹æ–‡ä»¶
            if self.current_angle == 0:
                model_file = "bishe01"
                target_dir = "D:\\æ¡Œé¢\\bishe01"
            elif self.current_angle == 90:
                model_file = "bishe02"
                target_dir = "D:\\æ¡Œé¢\\bishe02"
            else:  # 180åº¦
                model_file = "bishe03"
                target_dir = "D:\\æ¡Œé¢\\bishe03"

            # åˆ›å»ºè¾“å‡ºè·¯å¾„
            output_path = os.path.join(MODEL_OUTPUT_DIR, f"{model_file}.glb")

            # è·å–å½“å‰åˆ†è¾¨ç‡ä¿¡æ¯
            resolution_info = self.get_resolution_by_angle(self.current_angle)

            # åˆ›å»ºæ—‹è½¬æ ‡è®°æ–‡ä»¶
            rotation_info = {
                "angle": self.current_angle,
                "timestamp": datetime.now().isoformat(),
                "model_type": f"{model_file}_rotated",
                "target_directory": target_dir,
                "resolution": f"{resolution_info['width']}Ã—{resolution_info['height']}",
                "resolution_mode": resolution_info["mode"],
                "hardware_controlled": True  # æ ‡è®°ä¸ºç¡¬ä»¶æ§åˆ¶
            }

            info_file = output_path.replace('.glb', f'_rotation_{self.current_angle}.json')
            with open(info_file, 'w', encoding='utf-8') as f:
                json.dump(rotation_info, f, indent=2)

            print(f"âœ… ç”Ÿæˆæ¨¡å‹åˆ°: {target_dir}")
            print(f"ğŸ“ æ—‹è½¬æ¨¡å‹ä¿¡æ¯å·²ä¿å­˜: {info_file}")

        except Exception as e:
            print(f"âŒ ç”Ÿæˆæ—‹è½¬æ¨¡å‹æ—¶å‡ºé”™: {e}")

    def get_current_status(self):
        """è·å–å½“å‰æ—‹é’®çŠ¶æ€"""
        resolution_info = self.get_resolution_by_angle(self.current_angle)
        return {
            "angle": self.current_angle,
            "resolution_mode": self.current_resolution,
            "width": resolution_info["width"],
            "height": resolution_info["height"],
            "hardware_connected": self.serial_connection is not None,
            "stable": len(self.angle_buffer) >= self.buffer_size
        }

    def disconnect(self):
        """æ–­å¼€Arduinoè¿æ¥"""
        self.active = False
        if self.serial_connection:
            self.serial_connection.close()
            print("ğŸ”Œ Arduino Leonardoè¿æ¥å·²æ–­å¼€")


# å…¨å±€æ—‹é’®æ§åˆ¶å®ä¾‹
knob_system = KnobControlSystem()


# ========== ä¼˜åŒ–çš„è¯­éŸ³è¯†åˆ«ç±» ==========
class EnhancedSpeechRecognizer:
    """å¢å¼ºçš„è¯­éŸ³è¯†åˆ«ç³»ç»Ÿ - ä½¿ç”¨å¤šç§å¼•æ“æé«˜å‡†ç¡®æ€§"""

    def __init__(self):
        self.recognizer = sr.Recognizer()
        self.microphone = sr.Microphone()
        self.vosk_model = None
        self.vosk_rec = None
        self.audio_interface = None

        # ä¼˜åŒ–è¯†åˆ«å‚æ•°
        self.recognizer.energy_threshold = SPEECH_CONFIG["energy_threshold"]
        self.recognizer.dynamic_energy_threshold = SPEECH_CONFIG["dynamic_energy_threshold"]
        self.recognizer.pause_threshold = SPEECH_CONFIG["pause_threshold"]
        self.recognizer.phrase_threshold = SPEECH_CONFIG["phrase_threshold"]
        self.recognizer.non_speaking_duration = SPEECH_CONFIG["non_speaking_duration"]

        print("ğŸ¤ åˆå§‹åŒ–å¢å¼ºè¯­éŸ³è¯†åˆ«ç³»ç»Ÿ...")
        self.calibrate_microphone()

        if SPEECH_CONFIG["use_vosk_fallback"]:
            self.init_vosk_fallback()

    def calibrate_microphone(self):
        """æ ¡å‡†éº¦å…‹é£"""
        print("ğŸ”§ æ­£åœ¨æ ¡å‡†éº¦å…‹é£...")
        try:
            with self.microphone as source:
                self.recognizer.adjust_for_ambient_noise(source, duration=2)
            print(f"âœ… éº¦å…‹é£æ ¡å‡†å®Œæˆï¼Œèƒ½é‡é˜ˆå€¼: {self.recognizer.energy_threshold}")
        except Exception as e:
            print(f"âš ï¸ éº¦å…‹é£æ ¡å‡†å¤±è´¥: {e}")

    def init_vosk_fallback(self):
        """åˆå§‹åŒ–Voskä½œä¸ºå¤‡ç”¨"""
        try:
            if os.path.exists(VOSK_MODEL_PATH):
                import vosk
                vosk.SetLogLevel(-1)
                self.vosk_model = vosk.Model(VOSK_MODEL_PATH)
                self.vosk_rec = vosk.KaldiRecognizer(self.vosk_model, 16000)
                self.audio_interface = pyaudio.PyAudio()
                print("âœ… Voskå¤‡ç”¨å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
            else:
                print("âš ï¸ Voskæ¨¡å‹è·¯å¾„ä¸å­˜åœ¨ï¼Œè·³è¿‡å¤‡ç”¨å¼•æ“")
        except Exception as e:
            print(f"âš ï¸ Voskå¤‡ç”¨å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")

    def recognize_speech_google(self, audio_data):
        """ä½¿ç”¨Googleè¯­éŸ³è¯†åˆ«"""
        try:
            text = self.recognizer.recognize_google(audio_data, language='zh-CN')
            return text.strip()
        except sr.UnknownValueError:
            return None
        except sr.RequestError as e:
            print(f"âš ï¸ Googleè¯­éŸ³è¯†åˆ«æœåŠ¡é”™è¯¯: {e}")
            return None

    def recognize_speech_vosk(self, audio_data):
        """ä½¿ç”¨Voskç¦»çº¿è¯†åˆ«ä½œä¸ºå¤‡ç”¨"""
        if not self.vosk_rec:
            return None

        try:
            wav_data = audio_data.get_wav_data(convert_rate=16000, convert_width=2)

            if self.vosk_rec.AcceptWaveform(wav_data):
                result = json.loads(self.vosk_rec.Result())
                return result.get('text', '').strip()
            else:
                partial = json.loads(self.vosk_rec.PartialResult())
                return partial.get('partial', '').strip()

        except Exception as e:
            print(f"âš ï¸ Voskè¯†åˆ«é”™è¯¯: {e}")
            return None

    def listen_and_recognize(self):
        """ç›‘å¬å¹¶è¯†åˆ«è¯­éŸ³"""
        try:
            print("ğŸ¤ å¼€å§‹ç›‘å¬è¯­éŸ³...")

            with self.microphone as source:
                audio = self.recognizer.listen(
                    source,
                    timeout=SPEECH_CONFIG["timeout"],
                    phrase_time_limit=SPEECH_CONFIG["phrase_timeout"]
                )

            print("ğŸ” æ­£åœ¨è¯†åˆ«è¯­éŸ³...")

            # é¦–å…ˆå°è¯•Googleè¯†åˆ«
            if SPEECH_CONFIG["use_google_speech"]:
                text = self.recognize_speech_google(audio)
                if text and len(text) > 1:
                    print(f"âœ… Googleè¯†åˆ«ç»“æœ: {text}")
                    return text

            # å¦‚æœGoogleå¤±è´¥ï¼Œå°è¯•Vosk
            if SPEECH_CONFIG["use_vosk_fallback"]:
                text = self.recognize_speech_vosk(audio)
                if text and len(text) > 1:
                    print(f"âœ… Voskå¤‡ç”¨è¯†åˆ«ç»“æœ: {text}")
                    return text

            print("ğŸ”‡ æœªè¯†åˆ«åˆ°æœ‰æ•ˆè¯­éŸ³")
            return None

        except sr.WaitTimeoutError:
            print("â° è¯­éŸ³ç›‘å¬è¶…æ—¶")
            return None
        except Exception as e:
            print(f"âŒ è¯­éŸ³è¯†åˆ«é”™è¯¯: {e}")
            return None

# ========== Text Display Classes ==========
class TextDisplayApp(tk.Tk):
    def __init__(self, arduino_port='COM13'):
        super().__init__()
        self.title("å®æ—¶æ˜¾ç¤ºæ—‹é’®è§’åº¦")
        self.configure(bg="black")

        # ä¿å­˜Arduinoç«¯å£
        self.arduino_port = arduino_port

        # çª—å£è®¾ç½® - è®¾ç½®ä¸ºåŠå±æ˜¾ç¤º
        self.geometry("960x1080+0+0")  # å·¦åŠå±

        # åˆ›å»ºæ–‡æœ¬åŒºåŸŸæ˜¾ç¤ºè¯†åˆ«çš„è¯­éŸ³
        self.text_area = tk.Text(self, wrap=tk.WORD, bg="black", fg="white",
                                 font=("Microsoft YaHei", 16), padx=10, pady=10)
        self.text_area.pack(fill="both", expand=True)

        # æ·»åŠ ESCé”®å…³é—­ç¨‹åºçš„ç»‘å®š
        self.bind("<Escape>", self.on_closing)
        self.protocol("WM_DELETE_WINDOW", self.on_closing)

        # åŠ è½½åŒ…å«è¯†åˆ«è¯­éŸ³çš„æ–‡æœ¬æ–‡ä»¶
        self.text_file = VOICE_TEXT_FILE
        self.text_data = ""
        self.original_text = ""
        self.texts_to_restore = []

        # ä½¿ç”¨æ–°çš„è¯­éŸ³è¯†åˆ«ç³»ç»Ÿ
        self.speech_recognizer = EnhancedSpeechRecognizer()
        self.speech_recognition_active = False

        self.energy_threshold = 500  # é»˜è®¤é˜ˆå€¼

        # ç‰¹æ®Šç¬¦å·è®¡æ•°
        self.symbol_count = 0
        self.total_char_count = 0
        self.next_symbol_change = time.time() + random.uniform(1, 3)
        self.current_tags = []

        # å›¾ç‰‡UIå¼•ç”¨
        self.image_app = None

        # åˆå§‹åŒ–æ—‹é’®æ§åˆ¶ç³»ç»Ÿ - è¿æ¥çœŸå®ç¡¬ä»¶
        print("ğŸ”Œ æ­£åœ¨è¿æ¥Arduino Leonardoç¡¬ä»¶æ—‹é’®...")
        # å°è¯•COM9ç«¯å£ï¼ˆArduino Leonardoï¼‰ï¼Œå¦‚æœå¤±è´¥åˆ™å°è¯•å…¶ä»–ç«¯å£
        knob_success = False
        for port_try in ['COM13', self.arduino_port, 'COM3', 'COM4', 'COM5']:
            print('T------',port_try)
            try:
                print('O-----',port_try)
                knob_success = knob_system.initialize(port=port_try)  # è®¾ç½®ä¸º COM13
                if knob_success:
                    break
            except:
                print('C----',port_try)
                continue

        if not knob_success:
            print("âš ï¸ Arduino Leonardoè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç¡¬ä»¶è¿æ¥")
            print("ğŸ’¡ æç¤ºï¼šç¨‹åºä»å¯æ­£å¸¸å·¥ä½œï¼Œä½†æ— æ³•æ§åˆ¶åˆ†è¾¨ç‡")
            print("ğŸ”§ è¯·æ£€æŸ¥:")
            print("   1. Arduino Leonardo USBçº¿æ˜¯å¦è¿æ¥")
            print("   2. Arduinoæ˜¯å¦æ­£ç¡®ä¸Šä¼ äº†æ—‹é’®ä»£ç ")
            print("   3. ä¸²å£é©±åŠ¨æ˜¯å¦æ­£ç¡®å®‰è£…")
            print("   4. ç«¯å£æ˜¯å¦ä¸ºCOM9")

        # åˆå§‹åŒ–ç»„ä»¶
        self.update_text_display()
        self.setup_file_watcher()

        # å¯åŠ¨å„ç§æ•ˆæœ
        self.after(1000, self.random_highlight_text)
        self.after(1000, self.restore_original_text)
        self.after(1000, self.change_random_symbols)
        self.randomize_text_changes()

        # è‡ªåŠ¨å¯åŠ¨è¯­éŸ³è¯†åˆ«
        self.after(2000, self.auto_start_speech_recognition)

        # æ˜¾ç¤ºåˆå§‹æ—‹é’®çŠ¶æ€
        if knob_success:
            self.after(3000, self.show_initial_knob_status)

    def show_initial_knob_status(self):
        """æ˜¾ç¤ºåˆå§‹æ—‹é’®çŠ¶æ€"""
        if knob_system.active:
            status = knob_system.get_current_status()
            print(
                f"ğŸ›ï¸ Arduino Leonardoæ—‹é’®å·²è¿æ¥: {status['angle']}Â° | åˆ†è¾¨ç‡: {status['width']}Ã—{status['height']} | æ¨¡å¼: {status['resolution_mode']}")
            print("ğŸ¯ è¯·æ‰‹åŠ¨æ—‹è½¬Leonardoç¡¬ä»¶æ—‹é’®æ¥åˆ‡æ¢è§’åº¦å’Œåˆ†è¾¨ç‡")
        else:
            print("âš ï¸ Arduino Leonardoç¡¬ä»¶æ—‹é’®æœªè¿æ¥ï¼Œå°†ä½¿ç”¨é»˜è®¤åˆ†è¾¨ç‡è®¾ç½®")

    def set_image_app(self, image_app):
        """è®¾ç½®å›¾ç‰‡UIçš„å¼•ç”¨"""
        self.image_app = image_app

    def calibrate_audio_threshold(self):
        """æ ¡å‡†éŸ³é¢‘é˜ˆå€¼"""
        print("ğŸ”§ æ­£åœ¨æ ¡å‡†éŸ³é¢‘é˜ˆå€¼...")
        print("ğŸ“¢ è¯·ä¿æŒå®‰é™5ç§’é’Ÿ...")

        if not self.audio_interface:
            return 300  # é»˜è®¤é˜ˆå€¼

        try:
            FORMAT = pyaudio.paInt16
            CHANNELS = 1
            RATE = 16000
            CHUNK = 4000

            stream = self.audio_interface.open(
                format=FORMAT, channels=CHANNELS, rate=RATE,
                input=True, frames_per_buffer=CHUNK
            )

            energy_samples = []
            start_time = time.time()

            while time.time() - start_time < 5:  # é‡‡æ ·5ç§’
                data = stream.read(CHUNK, exception_on_overflow=False)
                audio_data = np.frombuffer(data, dtype=np.int16)
                energy = self.calculate_audio_energy(audio_data)
                energy_samples.append(energy)
                time.sleep(0.1)

            stream.stop_stream()
            stream.close()

            # è®¡ç®—èƒŒæ™¯å™ªéŸ³æ°´å¹³
            avg_noise = np.mean(energy_samples)
            max_noise = np.max(energy_samples)

            # è®¾ç½®é˜ˆå€¼ä¸ºèƒŒæ™¯å™ªéŸ³çš„3-5å€
            threshold = max(avg_noise * 4, max_noise * 2, 300)

            print(f"ğŸ”§ æ ¡å‡†å®Œæˆ:")
            print(f"   å¹³å‡èƒŒæ™¯å™ªéŸ³: {avg_noise:.0f}")
            print(f"   æœ€å¤§èƒŒæ™¯å™ªéŸ³: {max_noise:.0f}")
            print(f"   è®¾ç½®é˜ˆå€¼: {threshold:.0f}")

            return threshold

        except Exception as e:
            print(f"âŒ æ ¡å‡†å¤±è´¥: {e}")
            return 300  # è¿”å›é»˜è®¤é˜ˆå€¼

    def auto_start_speech_recognition(self):
        """è‡ªåŠ¨å¯åŠ¨è¯­éŸ³è¯†åˆ«"""
        print("ğŸ”„ è‡ªåŠ¨å¯åŠ¨è¯­éŸ³è¯†åˆ«...")
        if self.init_vosk():  # ç¡®ä¿Voskå·²åˆå§‹åŒ–
            print("ğŸ”§ å¼€å§‹éŸ³é¢‘é˜ˆå€¼æ ¡å‡†...")
            self.energy_threshold = self.calibrate_audio_threshold()
            print(f"âœ… é˜ˆå€¼æ ¡å‡†å®Œæˆï¼Œè®¾ç½®ä¸º: {self.energy_threshold}")
        self.start_speech_recognition()

    def start_speech_recognition(self):
            """å¯åŠ¨è¯­éŸ³è¯†åˆ«"""
            if not self.speech_recognition_active:
                self.speech_recognition_active = True
                self.speech_thread = threading.Thread(target=self.recognize_speech_loop)
                self.speech_thread.daemon = True
                self.speech_thread.start()
                print("ğŸ¤ ä¼˜åŒ–çš„è¯­éŸ³è¯†åˆ«å·²å¯åŠ¨")

    def recognize_speech_loop(self):
        """è¯­éŸ³è¯†åˆ«å¾ªç¯"""
        print("ğŸ¤ ä¼˜åŒ–çš„å®æ—¶è¯­éŸ³è¯†åˆ«å·²å¯åŠ¨ï¼Œå‡†ç¡®æ€§å¤§å¹…æå‡...")

        while self.speech_recognition_active:
            try:
                text = self.speech_recognizer.listen_and_recognize()

                if text and len(text) > 1:
                    print(f"âœ… è¯†åˆ«åˆ°è¯­éŸ³: {text}")

                    if not text.endswith("ã€‚") and not text.endswith("."):
                        text += "ã€‚"

                    self.original_text += text + "\n"
                    self.text_data += text + "\n"

                    self.save_text_to_file(text)
                    self.update_text_display()
                    self.simulate_random_deletion()

                    # è‡ªåŠ¨å¯åŠ¨å›¾åƒç”Ÿæˆå¤„ç†
                    self.auto_process_voice_to_image(text)

            except Exception as e:
                if self.speech_recognition_active:
                    print(f"âŒ è¯­éŸ³è¯†åˆ«å¾ªç¯å‡ºé”™: {e}")
                    time.sleep(1)

    def filter_input_text(text):
        """è¿‡æ»¤è¾“å…¥æ–‡æœ¬ä¸­çš„ä¸å½“å†…å®¹"""
        # å®šä¹‰éœ€è¦æ›¿æ¢çš„è¯æ±‡
        filter_words = {
            # å¯ä»¥æ·»åŠ éœ€è¦æ›¿æ¢çš„è¯æ±‡ï¼Œç”¨æ›´ä¸­æ€§çš„è¯æ›¿æ¢
            "æš´åŠ›": "å’Œå¹³",
            "æ‰“æ–—": "è¿åŠ¨",
            "è¡€è…¥": "çº¢è‰²"
            # æ ¹æ®éœ€è¦æ·»åŠ æ›´å¤šæ›¿æ¢è§„åˆ™
        }

        filtered_text = text
        for bad_word, replacement in filter_words.items():
            filtered_text = filtered_text.replace(bad_word, replacement)

        return filtered_text

    def auto_process_voice_to_image(self, text):
        """è‡ªåŠ¨å¤„ç†è¯­éŸ³åˆ°å›¾åƒç”Ÿæˆ - æ·»åŠ å†…å®¹è¿‡æ»¤"""
        global processing_queue, processing_lock, is_processing

        # è¿‡æ»¤è¾“å…¥æ–‡æœ¬
        filtered_text = filter_input_text(text)

        with processing_lock:
            processing_queue.append(filtered_text)  # ä½¿ç”¨è¿‡æ»¤åçš„æ–‡æœ¬

        if not is_processing:
            processing_thread = threading.Thread(target=self.process_queue)
            processing_thread.daemon = True
            processing_thread.start()

    def on_closing(self, event=None):
        """ç¨‹åºå…³é—­æ—¶çš„æ¸…ç†å·¥ä½œ"""
        print("ğŸ”„ æ­£åœ¨å…³é—­ç¨‹åº...")
        self.stop_speech_recognition()

        # æ–­å¼€Arduinoè¿æ¥
        if knob_system.active:
            knob_system.disconnect()

        if self.image_app:
            self.image_app.destroy()
        self.destroy()
        print("ğŸ‘‹ ç¨‹åºå·²å®‰å…¨é€€å‡º")



    def init_vosk(self):
        """åˆå§‹åŒ–Voskç¦»çº¿è¯­éŸ³è¯†åˆ«æ¨¡å‹"""
        try:
            print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–Voskè¯­éŸ³è¯†åˆ«æ¨¡å‹...")

            if not os.path.exists(VOSK_MODEL_PATH):
                print(f"âŒ Voskæ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {VOSK_MODEL_PATH}")
                print("è¯·ä¸‹è½½ä¸­æ–‡è¯­éŸ³è¯†åˆ«æ¨¡å‹ï¼š")
                print("1. è®¿é—®: https://alphacephei.com/vosk/models")
                print("2. ä¸‹è½½: vosk-model-cn-0.22.zip")
                print(f"3. è§£å‹åˆ°: {VOSK_MODEL_PATH}")
                return False

            def calibrate_audio_threshold(self):
                """æ ¡å‡†éŸ³é¢‘é˜ˆå€¼"""
                print("ğŸ”§ æ­£åœ¨æ ¡å‡†éŸ³é¢‘é˜ˆå€¼...")
                print("ğŸ“¢ è¯·ä¿æŒå®‰é™5ç§’é’Ÿ...")

                import numpy as np
                import time

                if not self.audio_interface:
                    return 300  # é»˜è®¤é˜ˆå€¼

                try:
                    FORMAT = pyaudio.paInt16
                    CHANNELS = 1
                    RATE = 16000
                    CHUNK = 4000

                    stream = self.audio_interface.open(
                        format=FORMAT, channels=CHANNELS, rate=RATE,
                        input=True, frames_per_buffer=CHUNK
                    )

                    energy_samples = []
                    start_time = time.time()

                    while time.time() - start_time < 5:  # é‡‡æ ·5ç§’
                        data = stream.read(CHUNK, exception_on_overflow=False)
                        audio_data = np.frombuffer(data, dtype=np.int16)
                        energy =self.calculate_audio_energy(audio_data)# np.sqrt(np.mean(audio_data ** 2))
                        energy_samples.append(energy)
                        time.sleep(0.1)

                    stream.stop_stream()
                    stream.close()

                    # è®¡ç®—èƒŒæ™¯å™ªéŸ³æ°´å¹³
                    avg_noise = np.mean(energy_samples)
                    max_noise = np.max(energy_samples)

                    # è®¾ç½®é˜ˆå€¼ä¸ºèƒŒæ™¯å™ªéŸ³çš„3-5å€
                    threshold = max(avg_noise * 4, max_noise * 2, 300)

                    print(f"ğŸ”§ æ ¡å‡†å®Œæˆ:")
                    print(f"   å¹³å‡èƒŒæ™¯å™ªéŸ³: {avg_noise:.0f}")
                    print(f"   æœ€å¤§èƒŒæ™¯å™ªéŸ³: {max_noise:.0f}")
                    print(f"   è®¾ç½®é˜ˆå€¼: {threshold:.0f}")

                    return threshold

                except Exception as e:
                    print(f"âŒ æ ¡å‡†å¤±è´¥: {e}")
                    return 300  # è¿”å›é»˜è®¤é˜ˆå€¼

            vosk.SetLogLevel(-1)
            self.vosk_model = vosk.Model(VOSK_MODEL_PATH)
            self.vosk_rec = vosk.KaldiRecognizer(self.vosk_model, 16000)
            self.audio_interface = pyaudio.PyAudio()

            print("âœ… Voskè¯­éŸ³è¯†åˆ«æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
            return True

        except Exception as e:
            print(f"âŒ Voskåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            return False

    def setup_file_watcher(self):
        """è®¾ç½®æ–‡ä»¶ç›‘è§†å™¨ä»¥æ£€æµ‹æ–‡æœ¬æ–‡ä»¶çš„å˜åŒ–"""
        try:
            self.observer = Observer()
            event_handler = FileChangeHandler(self.on_text_file_change)
            self.observer.schedule(event_handler, os.path.dirname(self.text_file), recursive=False)
            self.observer.start()
        except Exception as e:
            print(f"æ–‡ä»¶ç›‘è§†å™¨è®¾ç½®å¤±è´¥: {e}")

    def on_text_file_change(self):
        """æ–‡ä»¶å˜æ›´æ—¶é‡æ–°åŠ è½½æ–‡æœ¬å†…å®¹"""
        self.after(100, self.update_text_display)

    def update_text_display(self):
        """æ›´æ–°Textå°éƒ¨ä»¶ä¸­æ˜¾ç¤ºçš„æ–‡æœ¬"""
        try:
            self.text_area.delete(1.0, tk.END)
            self.text_area.insert(tk.END, self.text_data)
            self.text_area.see(tk.END)
            self.total_char_count = len(self.text_data)
            self.check_symbol_ratio()
        except Exception as e:
            print(f"è¯»å–æ–‡æœ¬æ–‡ä»¶æ—¶å‡ºé”™: {e}")

    def check_symbol_ratio(self):
        """æ£€æŸ¥ç‰¹æ®Šç¬¦å·æ¯”ä¾‹ï¼Œå¦‚æœè¶…è¿‡3%åˆ™å‡å°‘"""
        special_chars = "â–“â–’â–‘â– â–¡â—â—‹"  # ç®€åŒ–ç¬¦å·åˆ—è¡¨
        symbol_count = sum(1 for char in self.text_data if char in special_chars)
        symbol_ratio = symbol_count / max(1, self.total_char_count)

        if symbol_ratio > 0.03:  # é™ä½åˆ°3%
            # é™é»˜æ¸…ç†ï¼Œä¸è¾“å‡ºæ—¥å¿—
            for char in special_chars:
                if symbol_ratio <= 0.03:
                    break
                if char in self.text_data:
                    # ç§»é™¤å¤§éƒ¨åˆ†è¯¥å­—ç¬¦
                    self.text_data = self.text_data.replace(char, "")
                    symbol_count = sum(1 for c in self.text_data if c in special_chars)
                    symbol_ratio = symbol_count / max(1, len(self.text_data))

    def start_speech_recognition(self):
        """å¯åŠ¨è¯­éŸ³è¯†åˆ«"""
        if not self.speech_recognition_active and self.init_vosk():
            self.speech_recognition_active = True
            self.speech_thread = threading.Thread(target=self.recognize_speech)
            self.speech_thread.daemon = True
            self.speech_thread.start()
            print("ğŸ¤ è¯­éŸ³è¯†åˆ«å·²å¯åŠ¨ - å®æ—¶æ¨¡å¼")

    def stop_speech_recognition(self):
        """åœæ­¢è¯­éŸ³è¯†åˆ«"""
        self.speech_recognition_active = False
        print("ğŸ”‡ è¯­éŸ³è¯†åˆ«å·²åœæ­¢")

    def calculate_audio_energy(self,audio_data):
        """è®¡ç®—éŸ³é¢‘æ•°æ®çš„èƒ½é‡ï¼ˆRMSï¼‰ï¼Œå¤„ç†NaNå’Œæ— ç©·å¤§å€¼"""
        # æ£€æŸ¥å¹¶æ›¿æ¢NaNå€¼
        if np.isnan(audio_data).any():
            print("è­¦å‘Šï¼šéŸ³é¢‘æ•°æ®åŒ…å«NaNå€¼ï¼Œå°†è¢«æ›¿æ¢ä¸º0")
            audio_data = np.nan_to_num(audio_data)

        # æ£€æŸ¥å¹¶å¤„ç†æ— ç©·å¤§å€¼
        if np.isinf(audio_data).any():
            print("è­¦å‘Šï¼šéŸ³é¢‘æ•°æ®åŒ…å«æ— ç©·å¤§å€¼ï¼Œå°†è¢«è£å‰ª")
            audio_data = np.clip(audio_data, -np.finfo(float).max, np.finfo(float).max)

        # è®¡ç®—å‡æ–¹æ ¹èƒ½é‡
        squared = audio_data ** 2
        mean_squared = np.mean(squared)
        #np.sqrt(np.mean(audio_data ** 2))
        energy = mean_squared#np.sqrt(mean_squared)

        return energy



    def recognize_speech(self):
        """ä½¿ç”¨Voskè¿›è¡Œç¦»çº¿å®æ—¶è¯­éŸ³è¯†åˆ«å¹¶è‡ªåŠ¨å¤„ç†"""
        if not self.vosk_model or not self.vosk_rec or not self.audio_interface:
            return

        try:


            FORMAT = pyaudio.paInt16
            CHANNELS = 1
            RATE = 16000
            CHUNK = 4000

            # æŸ¥æ‰¾éº¦å…‹é£è®¾å¤‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
            microphone_index = None
            for i in range(self.audio_interface.get_device_count()):
                info = self.audio_interface.get_device_info_by_index(i)
                if (info['maxInputChannels'] > 0 and
                        ('éº¦å…‹é£' in info['name'] or 'Microphone' in info['name'] or 'mic' in info['name'].lower())):
                    microphone_index = i
                    print(f"âœ… æ‰¾åˆ°éº¦å…‹é£: {info['name']}")
                    break

            stream = self.audio_interface.open(
                format=FORMAT,
                channels=CHANNELS,
                rate=RATE,
                input=True,
                input_device_index=microphone_index,
                frames_per_buffer=CHUNK
            )

            print("ğŸ¤ å®æ—¶è¯­éŸ³è¯†åˆ«å·²å¯åŠ¨ï¼Œè¯·å¼€å§‹è®²è¯...")

            while self.speech_recognition_active:
               #try:

                    data = stream.read(CHUNK, exception_on_overflow=False)

                    import numpy as np
                    audio_data = np.frombuffer(data, dtype=np.int16)
                    audio_energy = self.calculate_audio_energy(audio_data)#np.sqrt(np.mean(audio_data ** 2))

                    # ä½¿ç”¨æ ¡å‡†çš„é˜ˆå€¼
                    if audio_energy > self.energy_threshold:
                        if self.vosk_rec.AcceptWaveform(data):
                            result = json.loads(self.vosk_rec.Result())
                            text = result.get('text', '').strip()

                            # åªå¤„ç†é•¿åº¦å¤§äº1çš„æ–‡æœ¬
                            if text and len(text) > 1:
                                print(f"âœ… Voskè¯†åˆ«çš„è¯­éŸ³ (èƒ½é‡:{audio_energy:.0f}): {text}")

                    # è®¡ç®—éŸ³é¢‘èƒ½é‡æ°´å¹³
                    audio_data = np.frombuffer(data, dtype=np.int16)
                    audio_energy =self.calculate_audio_energy(audio_data)# np.sqrt(np.mean(audio_data ** 2))

                    # è®¾ç½®èƒ½é‡é˜ˆå€¼ï¼šåªæœ‰è¶…è¿‡é˜ˆå€¼æ‰è¿›è¡Œè¯­éŸ³è¯†åˆ«
                    ENERGY_THRESHOLD = 300  # è°ƒæ•´è¿™ä¸ªå€¼ï¼Œæ ¹æ®ä½ çš„ç¯å¢ƒ

                    if audio_energy > ENERGY_THRESHOLD:
                        # åªæœ‰åœ¨æœ‰è¶³å¤ŸéŸ³é¢‘èƒ½é‡æ—¶æ‰è¿›è¡Œè¯†åˆ«
                        if self.vosk_rec.AcceptWaveform(data):
                            result = json.loads(self.vosk_rec.Result())
                            text = result.get('text', '').strip()
                            # åªå¤„ç†é•¿åº¦å¤§äº1çš„æ–‡æœ¬
                            if text and len(text) > 1:
                                print(f"âœ… Voskè¯†åˆ«çš„è¯­éŸ³ (èƒ½é‡:{audio_energy:.0f}): {text}")

                                if not text.endswith("ã€‚") and not text.endswith("."):
                                    text += "ã€‚"

                                self.original_text += text + "\n"
                                self.text_data += text + "\n"



                                self.save_text_to_file(text)
                                self.update_text_display()
                                self.simulate_random_deletion()

                                # è‡ªåŠ¨å¯åŠ¨å›¾åƒç”Ÿæˆå¤„ç†

                                self.auto_process_voice_to_image(text)
                            elif text:
                                print(f"ğŸ”‡ å¿½ç•¥å•å­—ç¬¦ (èƒ½é‡:{audio_energy:.0f}): {text}")
                    else:
                        # èƒ½é‡å¤ªä½ï¼Œè·³è¿‡è¯†åˆ«ï¼Œä½†å¯ä»¥æ˜¾ç¤ºèƒ½é‡æ°´å¹³ï¼ˆè°ƒè¯•ç”¨ï¼‰
                        if audio_energy > 50:  # åªæ˜¾ç¤ºæœ‰ä¸€å®šèƒ½é‡çš„
                            print(f"ğŸ”‡ èƒ½é‡ä¸è¶³ï¼Œè·³è¿‡è¯†åˆ« (èƒ½é‡:{audio_energy:.0f})")

                # except Exception as e:
                #     if self.speech_recognition_active:
                #         print(f"âŒ éŸ³é¢‘å¤„ç†å‡ºé”™: {str(e)}")
                #         time.sleep(0.1)

        except Exception as e:
            print(f"âŒ Voskè¯­éŸ³è¯†åˆ«è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        finally:
            try:
                if 'stream' in locals():
                    stream.stop_stream()
                    stream.close()
            except Exception as cleanup_error:
                print(f"âŒ æ¸…ç†éŸ³é¢‘æµæ—¶å‡ºé”™: {cleanup_error}")

    def save_text_to_file(self, text):
        """å°†è¯†åˆ«çš„æ–‡æœ¬ä¿å­˜åˆ°æŒ‡å®šæ–‡ä»¶"""
        try:
            os.makedirs(os.path.dirname(self.text_file), exist_ok=True)
            with open(self.text_file, "a", encoding="utf-8") as file:
                file.write(f"{text}\n")
        except Exception as e:
            print(f"âŒ å°†æ–‡æœ¬å†™å…¥æ–‡ä»¶æ—¶å‡ºé”™: {e}")

    def randomize_text_changes(self):
        """éšæœºä¿®æ”¹æ–‡æœ¬ä½¿å…¶åŠ¨æ€åŒ–"""
        if len(self.text_data) > 0 and random.random() < 0.05:  # å¤§å¹…é™ä½æ¦‚ç‡
            special_chars = "â–“â–’â–‘"  # è¿›ä¸€æ­¥ç®€åŒ–
            symbol_count = sum(1 for char in self.text_data if char in special_chars)
            symbol_ratio = symbol_count / max(1, len(self.text_data))

            if symbol_ratio < 0.02:  # æ›´ä¸¥æ ¼çš„é™åˆ¶
                glitch_chars = random.choice("â–“â–’â–‘")  # åªæ·»åŠ ä¸€ä¸ªå­—ç¬¦
                position = random.randint(0, max(0, len(self.text_data) - 1))
                self.text_data = self.text_data[:position] + glitch_chars + self.text_data[position:]
                self.update_text_display()

        self.after(random.randint(5000, 10000), self.randomize_text_changes)  # å¤§å¹…å¢åŠ é—´éš”

    def auto_process_voice_to_image(self, text):

        """è‡ªåŠ¨å¤„ç†è¯­éŸ³åˆ°å›¾åƒç”Ÿæˆ"""
        global processing_queue, processing_lock, is_processing

        with processing_lock:
            processing_queue.append(text)

        # å¦‚æœæ²¡æœ‰æ­£åœ¨å¤„ç†ï¼Œå¯åŠ¨å¤„ç†çº¿ç¨‹
        if not is_processing:
            processing_thread = threading.Thread(target=self.process_queue)
            processing_thread.daemon = True
            processing_thread.start()

    def process_queue(self):
        """å¤„ç†é˜Ÿåˆ—ä¸­çš„è¯­éŸ³æ–‡æœ¬"""
        global processing_queue, processing_lock, is_processing, image_text_mapping

        with processing_lock:
            is_processing = True

        try:
            while True:
                with processing_lock:
                    if not processing_queue:
                        break
                    text = processing_queue.pop(0)
                print(text,len(text))
                print(f"ğŸ”„ å¼€å§‹å¤„ç†è¯­éŸ³æ–‡æœ¬: {text}")

                # ç›´æ¥ä½¿ç”¨è¯­éŸ³æ–‡æœ¬ï¼Œä¸æ·»åŠ ä»»ä½•å‰ç¼€
                prompt_text = text
                print(f"ğŸ¤ ç›´æ¥ä½¿ç”¨è¯­éŸ³æ–‡æœ¬: {prompt_text}")

                # ç”Ÿæˆå›¾åƒ
                enhanced_prompt = prompt_text
                image_path = generate_image_with_comfyui(enhanced_prompt)

                if image_path:
                    # å¤åˆ¶åˆ°æ˜¾ç¤ºæ–‡ä»¶å¤¹
                    filename = os.path.basename(image_path)
                    dest_path = os.path.join(IMAGE_DISPLAY_FOLDER, filename)
                    shutil.copy2(image_path, dest_path)

                    # ä¿å­˜å›¾åƒä¸è¯­éŸ³æ–‡æœ¬çš„æ˜ å°„å…³ç³»
                    dest_filename = os.path.basename(dest_path)
                    image_text_mapping[dest_filename] = text.replace("ã€‚", "").strip()  # ç§»é™¤å¥å·ï¼Œä¿ç•™åŸå§‹æ–‡æœ¬
                    save_image_mapping()  # ä¿å­˜åˆ°æ–‡ä»¶

                    print(f"âœ… å›¾åƒå·²å¤åˆ¶åˆ°æ˜¾ç¤ºæ–‡ä»¶å¤¹: {dest_path}")
                    print(f"ğŸ·ï¸ å›¾åƒæ ‡ç­¾: {text}")

                    # ç”Ÿæˆ3Dæ¨¡å‹ï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡å›¾åƒæ˜¾ç¤ºï¼‰
                    model_thread = threading.Thread(target=lambda: generate_3d_model(image_path))
                    model_thread.daemon = True
                    model_thread.start()
                else:
                    print("âš ï¸ å›¾åƒç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡3Dæ¨¡å‹ç”Ÿæˆ")

                # ç¨ä½œå»¶è¿Ÿï¼Œé¿å…è¿‡äºé¢‘ç¹çš„å¤„ç†
                time.sleep(IMAGE_LOAD_DELAY)

        except Exception as e:
            print(f"âŒ å¤„ç†é˜Ÿåˆ—æ—¶å‡ºé”™: {str(e)}")
            traceback.print_exc()
        finally:
            with processing_lock:
                is_processing = False

    def translate_random_word(self, text):
        """éšæœºç¿»è¯‘å¥å­ä¸­çš„ä¸€ä¸ªè¯è¯­ä¸ºè‹±æ–‡"""
        try:
            session = create_requests_session()
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer "
            }

            words = text.split()
            if len(words) < 2:
                return text

            word_to_translate = random.choice(words)
            prompt = f"è¯·å°†ä»¥ä¸‹å¥å­ä¸­çš„è¯è¯­ã€Œ{word_to_translate}ã€ç¿»è¯‘æˆè‹±æ–‡ï¼ˆä»…ç¿»è¯‘è¿™ä¸€ä¸ªè¯ï¼Œä¿ç•™å…¶ä»–éƒ¨åˆ†ä¸å˜ï¼‰:\n\n{text}"

            payload = {
                "model": "deepseek-chat",
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.7,
                "max_tokens": 512
            }

            response = session.post(
                "https://api.deepseek.com/v1/chat/completions",
                headers=headers, json=payload, timeout=10
            )

            if response.status_code == 200:
                result = response.json()
                translated_text = result["choices"][0]["message"]["content"].strip()
                if not translated_text.endswith("ã€‚") and not translated_text.endswith("."):
                    translated_text += "ã€‚"
                return translated_text

        except Exception as e:
            print(f"âŒ ç¿»è¯‘æ–‡æœ¬å‡ºé”™: {str(e)}")
        return None

    def simulate_random_deletion(self):
        """æ¨¡æ‹Ÿéšæœºåˆ é™¤æ–‡æœ¬"""
        if random.random() < 0.1:
            if len(self.text_data) > 20:
                start_index = random.randint(0, len(self.text_data) - 20)
                length = random.randint(2, 10)
                end_index = min(start_index + length, len(self.text_data))
                self.text_data = self.text_data[:start_index] + self.text_data[end_index:]
                self.update_text_display()

    def change_random_symbols(self):
        """éšæœºå˜åŒ–ç‰¹æ®Šç¬¦å·"""
        try:
            current_time = time.time()
            if current_time >= self.next_symbol_change and len(self.text_data) > 10:
                strange_symbols = [
                    "â–“", "â–’", "â–‘", "â– ", "â–¡", "â—", "â—‹"  # ç®€åŒ–ç¬¦å·åˆ—è¡¨
                ]

                special_chars = "".join(strange_symbols)
                positions = [i for i, char in enumerate(self.text_data) if char in special_chars]

                if positions and random.random() < 0.3:  # é™ä½å˜åŒ–æ¦‚ç‡
                    position = random.choice(positions)
                    new_symbol = random.choice(strange_symbols)
                    self.text_data = self.text_data[:position] + new_symbol + self.text_data[position + 1:]
                elif random.random() < 0.1:  # é™ä½æ·»åŠ æ¦‚ç‡
                    symbol_count = sum(1 for char in self.text_data if char in special_chars)
                    symbol_ratio = symbol_count / max(1, len(self.text_data))
                    if symbol_ratio < 0.03:  # æ›´ä¸¥æ ¼çš„é™åˆ¶
                        position = random.randint(0, len(self.text_data) - 1)
                        symbol = random.choice(strange_symbols)
                        self.text_data = self.text_data[:position] + symbol + self.text_data[position:]

                self.next_symbol_change = current_time + random.uniform(3, 8)  # å¢åŠ é—´éš”æ—¶é—´
                self.update_text_display()
        except Exception as e:
            print(f"âŒ ç¬¦å·å˜åŒ–å‡ºé”™: {str(e)}")

        self.after(2000, self.change_random_symbols)  # å¢åŠ æ£€æŸ¥é—´éš”

    def random_highlight_text(self):
        """éšæœºé«˜äº®æ–‡æœ¬ä¸­çš„éƒ¨åˆ†å†…å®¹"""
        try:
            if len(self.text_data) > 10:
                for tag in self.current_tags:
                    self.text_area.tag_delete(tag)
                self.current_tags = []

                total_length = len(self.text_data)
                highlight_target = int(total_length * 0.1)
                highlighted_so_far = 0
                max_attempts = 20
                attempts = 0

                while highlighted_so_far < highlight_target and attempts < max_attempts:
                    attempts += 1
                    if len(self.text_data) <= 5:
                        break

                    start_index = random.randint(0, len(self.text_data) - 5)
                    remaining_text = len(self.text_data) - start_index
                    if remaining_text < 5:
                        continue

                    remaining = highlight_target - highlighted_so_far
                    max_length = min(30, remaining_text, remaining)
                    min_length = min(5, max_length)

                    if max_length <= min_length:
                        length = min_length
                    else:
                        length = random.randint(min_length, max_length)

                    end_index = start_index + length
                    tag_name = f"highlight_{random.randint(1, 10000)}"

                    self.text_area.tag_add(tag_name, f"1.{start_index}", f"1.{end_index}")
                    highlight_color = random.choice(["yellow", "#FFFF99", "#FFD700", "#FFFACD"])
                    self.text_area.tag_configure(tag_name, background=highlight_color)
                    self.current_tags.append(tag_name)
                    highlighted_so_far += length
        except Exception as e:
            print(f"âŒ é«˜äº®æ–‡æœ¬å‡ºé”™: {str(e)}")

        self.after(random.randint(1000, 3000), self.random_highlight_text)

    def restore_original_text(self):
        """å°†å¤„ç†åçš„æ–‡æœ¬æ¢å¤ä¸ºåŸå§‹æ–‡æœ¬"""
        try:
            current_time = time.time()
            texts_to_remove = []

            for restore_info in self.texts_to_restore:
                if current_time >= restore_info["time"]:
                    processed_text = restore_info["processed_text"]
                    original_text = restore_info["original_text"]

                    if processed_text in self.text_data:
                        self.text_data = self.text_data.replace(processed_text, original_text)
                        texts_to_remove.append(restore_info)

            for item in texts_to_remove:
                self.texts_to_restore.remove(item)

            if texts_to_remove:
                self.update_text_display()
        except Exception as e:
            print(f"âŒ æ¢å¤åŸå§‹æ–‡æœ¬å‡ºé”™: {str(e)}")

        self.after(1000, self.restore_original_text)

    def __del__(self):
        """ç¡®ä¿ç¨‹åºé€€å‡ºæ—¶è§‚å¯Ÿè€…çº¿ç¨‹åœæ­¢"""
        try:
            if hasattr(self, 'observer') and self.observer:
                self.observer.stop()
                self.observer.join()
        except Exception as e:
            print(f"âŒ åœæ­¢è§‚å¯Ÿè€…æ—¶å‡ºé”™: {e}")

        try:
            if hasattr(self, 'audio_interface') and self.audio_interface:
                self.audio_interface.terminate()
        except Exception as e:
            print(f"âŒ ç»ˆæ­¢éŸ³é¢‘æ¥å£æ—¶å‡ºé”™: {e}")


class FileChangeHandler(FileSystemEventHandler):
    """æ–‡ä»¶å˜æ›´çš„è‡ªå®šä¹‰å¤„ç†ç¨‹åº"""

    def __init__(self, callback):
        self.callback = callback

    def on_modified(self, event):
        """ç›‘æ§æ–‡ä»¶ä¿®æ”¹æ—¶è§¦å‘"""
        if (hasattr(self.callback, '__self__') and
                hasattr(self.callback.__self__, 'text_file') and
                event.src_path == self.callback.__self__.text_file):
            self.callback()


# ========== Image Display Classes ==========
class ImageChangeHandler(FileSystemEventHandler):
    def __init__(self, callback):
        self.callback = callback
        self.last_event_time = time.time()
        self.cooldown = 1.0

    def on_created(self, event):
        if event.is_directory:
            return
        if event.src_path.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):
            current_time = time.time()
            if current_time - self.last_event_time > self.cooldown:
                self.last_event_time = current_time
                self.callback()

    def on_deleted(self, event):
        if event.is_directory:
            return
        if event.src_path.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):
            current_time = time.time()
            if current_time - self.last_event_time > self.cooldown:
                self.last_event_time = current_time
                self.callback()


# ========== Enhanced Image Display Classes ==========
class DynamicLayoutApp(tk.Toplevel):
    def __init__(self, folder, parent):
        super().__init__(parent)
        self.title("Dynamic Layout Image Viewer")
        self.configure(bg="black")

        # çª—å£çŠ¶æ€ç®¡ç†
        self.is_fullscreen = False
        self.normal_geometry = "960x1080+960+0"  # è®°å½•æ­£å¸¸å¤§å°
        self.manual_layout = False  # æ˜¯å¦ä½¿ç”¨æ‰‹åŠ¨å¸ƒå±€

        # è®¾ç½®çª—å£ä¸ºæ— è¾¹æ¡†ï¼ˆé»‘è‰²é¡¶æ ï¼‰
        self.overrideredirect(False)  # ä¿ç•™çª—å£æ§åˆ¶æŒ‰é’®
        self.configure(bg="black")

        # åˆå§‹çª—å£è®¾ç½® - è®¾ç½®ä¸ºå³åŠå±æ˜¾ç¤º
        self.geometry(self.normal_geometry)

        # ç»‘å®šé”®ç›˜äº‹ä»¶
        self.bind("<KeyPress>", self.on_key_press)
        self.focus_set()  # ç¡®ä¿çª—å£å¯ä»¥æ¥æ”¶é”®ç›˜äº‹ä»¶

        # ç»‘å®šçª—å£å¤§å°å˜åŒ–äº‹ä»¶
        self.bind("<Configure>", self.on_window_resize)

        # ç»‘å®šæœ€å¤§åŒ–äº‹ä»¶
        self.bind("<Button-1>", self.on_click)  # å¯é€‰ï¼šåŒå‡»æœ€å¤§åŒ–

        self.canvas = tk.Canvas(self, bg="black", highlightthickness=0, bd=0)
        self.canvas.pack(fill="both", expand=True)

        self.folder =r"C:\111\ComfyUI-aki\ComfyUI-aki-v1.6\ComfyUI\output"
        self.loaded_images = []
        self.image_filenames = []
        self.tk_images = []
        self.image_items = []
        self.layout = {"rows": 1, "cols": 1}
        self.scroll_directions = []

        # çª—å£å°ºå¯¸å˜é‡
        self.current_width = 960
        self.current_height = 1080

        # å›¾åƒæ˜¾ç¤ºä¼˜åŒ– - å¢åŠ åˆ°50ä¸ª
        self.max_visible_images = 50  # å¢åŠ åˆ°50ä¸ªåŒæ—¶æ˜¾ç¤º
        self.image_cache = {}
        self.last_update_time = 0
        self.update_throttle = 0.05  # å‡å°‘æ›´æ–°èŠ‚æµæ—¶é—´ï¼Œæé«˜å“åº”æ€§

        # åŠ è½½åŒ…å«è¯†åˆ«è¯­éŸ³çš„æ–‡æœ¬æ–‡ä»¶
        self.text_file = VOICE_TEXT_FILE
        self.text_data = ""
        self.original_text = ""
        self.texts_to_restore = []


        # æ»šåŠ¨ç›¸å…³
        self.scroll_speed = 2  # æ»šåŠ¨é€Ÿåº¦
        self.scroll_active = True

        # Set up file watcher
        self.setup_file_watcher()

        # Initialize the interface
        self.load_images()
        self.update_layout()
        self.populate_canvas()
        self.scroll()

        # å¯åŠ¨åæ˜¾ç¤ºå¸®åŠ©
        self.after(1000, self.show_help)

        print(f"âœ… å……æ»¡å±å¹•çš„æ­£æ–¹å½¢å›¾ç‰‡UIå·²å¯åŠ¨")
        print("ğŸ”² æ‰€æœ‰å›¾ç‰‡ä¿æŒæ­£æ–¹å½¢æ˜¾ç¤ºï¼Œå……æ»¡æ•´ä¸ªå±å¹•")
        print("â™¾ï¸ æ”¯æŒæ— é™å¾ªç¯æ»šåŠ¨ï¼Œå³ä½¿å›¾ç‰‡ä¸è¶³ä¹Ÿä¼šè‡ªåŠ¨å¡«å……")
        print("ğŸ›ï¸ å¯è°ƒæ•´è¡Œåˆ—å¸ƒå±€:")
        print("   1-9é”®: å¿«é€Ÿè®¾ç½®NxNå¸ƒå±€")
        print("   +/-é”®: å¢å‡è¡Œåˆ—æ•°")
        print("   Ré”®: é‡ç½®è‡ªåŠ¨å¸ƒå±€")
        print("ğŸ–¥ï¸ F11: åˆ‡æ¢å…¨å± | ESC: é€€å‡ºå…¨å±")
        print("ğŸ® ç©ºæ ¼: æš‚åœæ»šåŠ¨ | Hé”®: æ˜¾ç¤ºå¸®åŠ©")

    def update_text_display(self):
        """æ›´æ–°Textå°éƒ¨ä»¶ä¸­æ˜¾ç¤ºçš„æ–‡æœ¬"""
        try:
            self.text_area.delete(1.0, tk.END)
            self.text_area.insert(tk.END, self.text_data)
            self.text_area.see(tk.END)
            self.total_char_count = len(self.text_data)
            self.check_symbol_ratio()
        except Exception as e:
            print(f"è¯»å–æ–‡æœ¬æ–‡ä»¶æ—¶å‡ºé”™: {e}")

    def on_text_file_change(self):
        """æ–‡ä»¶å˜æ›´æ—¶é‡æ–°åŠ è½½æ–‡æœ¬å†…å®¹"""
        self.after(100, self.update_text_display)

    def setup_file_watcher(self):
        """è®¾ç½®æ–‡ä»¶ç›‘è§†å™¨ä»¥æ£€æµ‹æ–‡æœ¬æ–‡ä»¶çš„å˜åŒ–"""
        try:
            self.observer = Observer()
            event_handler = FileChangeHandler(self.on_text_file_change)
            self.observer.schedule(event_handler, os.path.dirname(self.text_file), recursive=False)
            self.observer.start()
        except Exception as e:
            print(f"æ–‡ä»¶ç›‘è§†å™¨è®¾ç½®å¤±è´¥: {e}")

    def on_key_press(self, event):
        """å¤„ç†é”®ç›˜äº‹ä»¶"""
        if event.keysym == "F11":
            self.toggle_fullscreen()
        elif event.keysym == "Escape":
            if self.is_fullscreen:
                self.exit_fullscreen()
            else:
                # å¦‚æœä¸åœ¨å…¨å±ï¼ŒESCå…³é—­ç¨‹åº
                self.master.on_closing()
        elif event.keysym == "space":
            # ç©ºæ ¼é”®æš‚åœ/æ¢å¤æ»šåŠ¨
            self.scroll_active = not self.scroll_active
            print(f"ğŸ“º æ»šåŠ¨{'æš‚åœ' if not self.scroll_active else 'æ¢å¤'}")
        elif event.keysym in ["1", "2", "3", "4", "5", "6", "7", "8", "9"]:
            # æ•°å­—é”®å¿«é€Ÿè®¾ç½®è¡Œåˆ—å¸ƒå±€
            num = int(event.keysym)
            self.set_manual_layout(num, num)
        elif event.keysym == "equal" or event.keysym == "plus":
            # + é”®å¢åŠ è¡Œåˆ—æ•°
            self.adjust_layout(1)
        elif event.keysym == "minus":
            # - é”®å‡å°‘è¡Œåˆ—æ•°
            self.adjust_layout(-1)
        elif event.keysym == "r":
            # Ré”®é‡ç½®ä¸ºè‡ªåŠ¨å¸ƒå±€
            self.reset_auto_layout()
        elif event.keysym == "h":
            # Hé”®æ˜¾ç¤ºå¸®åŠ©
            self.show_help()

    def set_manual_layout(self, rows, cols):
        """æ‰‹åŠ¨è®¾ç½®è¡Œåˆ—å¸ƒå±€"""
        self.layout = {"rows": rows, "cols": cols}
        self.manual_layout = True
        print(f"ğŸ›ï¸ æ‰‹åŠ¨è®¾ç½®å¸ƒå±€: {rows}x{cols}")
        self.update_scroll_directions()
        self.populate_canvas()

    def adjust_layout(self, delta):
        """è°ƒæ•´å½“å‰å¸ƒå±€"""
        current_size = max(self.layout["rows"], self.layout["cols"])
        new_size = max(1, min(10, current_size + delta))
        self.set_manual_layout(new_size, new_size)

    def reset_auto_layout(self):
        """é‡ç½®ä¸ºè‡ªåŠ¨å¸ƒå±€"""
        self.manual_layout = False
        print("ğŸ”„ é‡ç½®ä¸ºè‡ªåŠ¨å¸ƒå±€æ¨¡å¼")
        self.update_layout()
        self.populate_canvas()

    def show_help(self):
        """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
        print("=" * 50)
        print("ğŸ® å›¾ç‰‡UIæ§åˆ¶å¸®åŠ©:")
        print("F11     - åˆ‡æ¢å…¨å±")
        print("ESC     - é€€å‡ºå…¨å±/å…³é—­ç¨‹åº")
        print("ç©ºæ ¼    - æš‚åœ/æ¢å¤æ»šåŠ¨")
        print("1-9     - å¿«é€Ÿè®¾ç½®NxNå¸ƒå±€")
        print("+       - å¢åŠ è¡Œåˆ—æ•°")
        print("-       - å‡å°‘è¡Œåˆ—æ•°")
        print("R       - é‡ç½®ä¸ºè‡ªåŠ¨å¸ƒå±€")
        print("H       - æ˜¾ç¤ºæ­¤å¸®åŠ©")
        print("=" * 50)

    def on_click(self, event):
        """å¤„ç†ç‚¹å‡»äº‹ä»¶ - å¯é€‰çš„åŒå‡»æœ€å¤§åŒ–"""
        # è¿™é‡Œå¯ä»¥æ·»åŠ åŒå‡»æ£€æµ‹é€»è¾‘
        pass

    def toggle_fullscreen(self):
        """åˆ‡æ¢å…¨å±çŠ¶æ€"""
        if self.is_fullscreen:
            self.exit_fullscreen()
        else:
            self.enter_fullscreen()

    def enter_fullscreen(self):
        """è¿›å…¥å…¨å±æ¨¡å¼"""
        if not self.is_fullscreen:
            # è®°å½•å½“å‰çª—å£å‡ ä½•ä¿¡æ¯
            self.normal_geometry = self.geometry()

            # è·å–å±å¹•å°ºå¯¸
            screen_width = self.winfo_screenwidth()
            screen_height = self.winfo_screenheight()

            # è®¾ç½®å…¨å±
            self.geometry(f"{screen_width}x{screen_height}+0+0")
            self.attributes('-topmost', True)  # ç½®é¡¶
            self.overrideredirect(True)  # å®Œå…¨æ— è¾¹æ¡†

            self.is_fullscreen = True
            self.current_width = screen_width
            self.current_height = screen_height

            print(f"ğŸ–¥ï¸ å·²è¿›å…¥å…¨å±æ¨¡å¼: {screen_width}x{screen_height}")

            # å¦‚æœä¸æ˜¯æ‰‹åŠ¨å¸ƒå±€æ¨¡å¼ï¼Œé‡æ–°è®¡ç®—å¸ƒå±€
            if not self.manual_layout:
                self.update_layout()

            # é‡æ–°å¸ƒå±€
            self.after_idle(self.populate_canvas)

    def exit_fullscreen(self):
        """é€€å‡ºå…¨å±æ¨¡å¼"""
        if self.is_fullscreen:
            # æ¢å¤çª—å£
            self.overrideredirect(False)
            self.attributes('-topmost', False)
            self.geometry(self.normal_geometry)

            self.is_fullscreen = False

            # ä»å‡ ä½•å­—ç¬¦ä¸²ä¸­æå–å°ºå¯¸
            try:
                size_part = self.normal_geometry.split('+')[0]
                width, height = map(int, size_part.split('x'))
                self.current_width = width
                self.current_height = height
            except:
                self.current_width = 960
                self.current_height = 1080

            print(f"ğŸ–¥ï¸ å·²é€€å‡ºå…¨å±æ¨¡å¼: {self.current_width}x{self.current_height}")

            # å¦‚æœä¸æ˜¯æ‰‹åŠ¨å¸ƒå±€æ¨¡å¼ï¼Œé‡æ–°è®¡ç®—å¸ƒå±€
            if not self.manual_layout:
                self.update_layout()

            # é‡æ–°å¸ƒå±€
            self.after_idle(self.populate_canvas)

    def on_window_resize(self, event):
        """å¤„ç†çª—å£å¤§å°å˜åŒ–"""
        if event.widget == self and not self.is_fullscreen:  # åªåœ¨éå…¨å±æ¨¡å¼å¤„ç†resize
            new_width = event.width
            new_height = event.height

            # æ£€æŸ¥æ˜¯å¦çœŸçš„æ”¹å˜äº†å¤§å°
            if abs(new_width - self.current_width) > 10 or abs(new_height - self.current_height) > 10:
                self.current_width = new_width
                self.current_height = new_height

                # å¦‚æœä¸æ˜¯æ‰‹åŠ¨å¸ƒå±€æ¨¡å¼ï¼Œé‡æ–°è®¡ç®—å¸ƒå±€
                if not self.manual_layout:
                    self.update_layout()

                # é‡æ–°ç»˜åˆ¶å›¾åƒï¼Œä½¿ç”¨èŠ‚æµ
                current_time = time.time()
                if current_time - self.last_update_time > self.update_throttle:
                    self.last_update_time = current_time
                    self.after_idle(self.populate_canvas)

    def calculate_optimal_layout(self, num_images):
        """æ ¹æ®å›¾ç‰‡æ•°é‡è·å–é¢„å®šä¹‰çš„å®Œç¾å¸ƒå±€"""
        if num_images <= 0:
            return {"rows": 1, "cols": 1}

        # ç›´æ¥ä»é…ç½®è¡¨æŸ¥æ‰¾æœ€æ¥è¿‘çš„å¸ƒå±€
        if num_images in LAYOUT_TABLE:
            return LAYOUT_TABLE[num_images]

        # å¦‚æœä¸åœ¨è¡¨ä¸­ï¼Œæ‰¾æœ€æ¥è¿‘çš„è¾ƒå¤§å€¼
        for count in sorted(LAYOUT_TABLE.keys()):
            if count >= num_images:
                return LAYOUT_TABLE[count]

        # è¶…è¿‡æœ€å¤§å€¼ï¼Œä½¿ç”¨æœ€å¤§é…ç½®
        return LAYOUT_TABLE[50]

    def update_layout(self):
        """æ ¹æ®å›¾ç‰‡æ•°é‡å’Œå±å¹•å°ºå¯¸åŠ¨æ€æ›´æ–°å¸ƒå±€"""
        if not self.manual_layout:  # åªåœ¨éæ‰‹åŠ¨æ¨¡å¼ä¸‹è‡ªåŠ¨è®¡ç®—å¸ƒå±€
            num_images = len(self.loaded_images)
            self.layout = self.calculate_optimal_layout(num_images)

        self.update_scroll_directions()

        print(f"ğŸ“ å¸ƒå±€: {self.layout['rows']}x{self.layout['cols']} (å±å¹•: {self.current_width}x{self.current_height})")
        if self.manual_layout:
            print("ğŸ›ï¸ æ‰‹åŠ¨å¸ƒå±€æ¨¡å¼")
        else:
            print("ğŸ”„ è‡ªåŠ¨å¸ƒå±€æ¨¡å¼")

    def update_scroll_directions(self):
        """æ›´æ–°æ»šåŠ¨æ–¹å‘"""
        self.scroll_directions = []
        for i in range(self.layout["cols"]):
            direction = 1 if i % 2 == 1 else -1
            self.scroll_directions.append(direction)

    def get_image_size(self):
        """è®¡ç®—å›¾åƒå¤§å°ç¡®ä¿å®Œå…¨å æ»¡UI"""
        rows = self.layout["rows"]
        cols = self.layout["cols"]
        if rows == 0 or cols == 0:
            return 300, 300

        # è®¡ç®—æ¯ä¸ªå›¾ç‰‡çš„ç²¾ç¡®å°ºå¯¸ï¼Œç¡®ä¿æ— é»‘è¾¹
        width = self.current_width // cols
        height = self.current_height // rows

        # ä½¿ç”¨è¾ƒå°å€¼ç¡®ä¿æ­£æ–¹å½¢ï¼Œä½†å…è®¸å®Œå…¨å¡«å……
        size = min(width, height)
        return size, size

    def draw_number(self, img, index, filename=None):
        """åœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶ä¿¡æ¯æ ‡ç­¾ - ç›¸å¯¹ä½ç½®ç¡®ä¿ä¸åç§»"""
        img_width, img_height = img.size

        # æ ¹æ®å›¾ç‰‡å°ºå¯¸åŠ¨æ€è°ƒæ•´å­—ä½“å¤§å°
        base_font_size = min(img_width, img_height) // 50
        font_size_large = max(12, min(32, base_font_size * 2))
        font_size_small = max(8, min(18, base_font_size))

        label = f"{str(index).zfill(8)}X"

        # ç”Ÿæˆéšæœºåæ ‡
        lat = random.uniform(-90, 90)
        lon = random.uniform(-180, 180)
        coordinates = f"{lat:.4f}Â° N {lon:.4f}Â° E"

        # ç”Ÿæˆæ—¶é—´æ ‡ç­¾
        current_time = datetime.now(BEIJING_TZ)
        hour = current_time.hour
        time_labels = {
            (23, 1): "å­ æ—¶", (1, 3): "ä¸‘ æ—¶", (3, 5): "å¯… æ—¶", (5, 7): "å¯ æ—¶",
            (7, 9): "è¾° æ—¶", (9, 11): "å·³ æ—¶", (11, 13): "åˆ æ—¶", (13, 15): "æœª æ—¶",
            (15, 17): "ç”³ æ—¶", (17, 19): "é…‰ æ—¶", (19, 21): "æˆŒ æ—¶", (21, 23): "äº¥ æ—¶"
        }

        time_label = "äº¥ æ—¶"  # é»˜è®¤
        for (start, end), label_text in time_labels.items():
            if start <= hour < end or (start == 23 and (hour >= 23 or hour < 1)):
                time_label = label_text
                break

        time_date = current_time.strftime(
            f"{time_label} {current_time.strftime('%I:%M%p')} {current_time.strftime('%m.%d.%Y')}")

        # è·å–å¯¹åº”çš„è¯­éŸ³å…³é”®è¯
        keyword = self.get_image_keyword(filename) if filename else "ç”Ÿæˆå›¾åƒ"

        draw = ImageDraw.Draw(img)
        try:
            font_large = ImageFont.truetype("msyh.ttc", font_size_large)
            font_small = ImageFont.truetype("msyh.ttc", font_size_small)
        except:
            font_large = ImageFont.load_default()
            font_small = ImageFont.load_default()

        # ä½¿ç”¨ç›¸å¯¹ä½ç½®ç»˜åˆ¶æ–‡å­—ï¼Œç¡®ä¿ä¸å› çª—å£å˜åŒ–è€Œåç§»
        margin = max(5, img_width // 100)  # åŠ¨æ€è¾¹è·

        # å·¦ä¸Šè§’ - ç¼–å·
        draw.text((margin, margin), label, fill="white", font=font_large)

        # å³ä¸Šè§’ - åæ ‡
        try:
            coord_bbox = font_small.getbbox(coordinates)
            coord_width = coord_bbox[2] - coord_bbox[0]
        except:
            coord_width = len(coordinates) * font_size_small // 2

        draw.text((img_width - coord_width - margin, margin), coordinates, fill="white", font=font_small)

        # å·¦ä¸‹è§’ - å…³é”®è¯
        try:
            keyword_bbox = font_small.getbbox(f"Key Word: [{keyword}]")
            keyword_height = keyword_bbox[3] - keyword_bbox[1]
        except:
            keyword_height = font_size_small

        draw.text((margin, img_height - keyword_height * 2 - margin),
                  f"Key Word: [{keyword}]", fill="white", font=font_small)

        # å·¦ä¸‹è§’ - æ—¶é—´
        draw.text((margin, img_height - keyword_height - margin // 2),
                  time_date, fill="white", font=font_small)

        return img

    def populate_canvas(self):
        """å®Œç¾å¡«å……canvasï¼Œæ— é»‘è‰²åŒºåŸŸ"""
        self.canvas.delete("all")
        self.tk_images.clear()
        self.image_items.clear()

        if not self.loaded_images:
            img_size, _ = self.get_image_size()
            blank = Image.new("RGB", (img_size, img_size), "black")
            blank_with_number = self.draw_number(blank, 1, "default_black.png")
            self.loaded_images = [blank_with_number]
            self.image_filenames = ["default_black.png"]

        img_size, _ = self.get_image_size()

        # å…³é”®ï¼šè®¡ç®—å®é™…å¯ä»¥æ”¾ç½®çš„å›¾ç‰‡æ•°é‡æ¥å¡«æ»¡UI
        max_displayable = self.layout["rows"] * self.layout["cols"]

        # å¦‚æœå›¾ç‰‡ä¸è¶³ï¼Œå¤åˆ¶ç°æœ‰å›¾ç‰‡æ¥å¡«æ»¡å¸ƒå±€
        display_images = self.loaded_images.copy()
        if len(display_images) < max_displayable:
            original_count = len(display_images)
            for i in range(max_displayable - original_count):
                display_images.append(self.loaded_images[i % original_count])

        # ç»˜åˆ¶å›¾ç‰‡ï¼Œç¡®ä¿å®Œå…¨å¡«æ»¡UI
        for i in range(min(max_displayable, len(display_images))):
            img = display_images[i].copy()
            img = img.resize((img_size, img_size), Image.Resampling.LANCZOS)

            # æ·»åŠ æ ‡ç­¾
            filename = self.image_filenames[i % len(self.image_filenames)] if self.image_filenames else None
            img = self.draw_number(img, i + 1, filename)

            # è®¡ç®—ä½ç½®ï¼šå®Œå…¨æ— é—´éš™å¡«å……
            row = i // self.layout["cols"]
            col = i % self.layout["cols"]

            x_pos = col * img_size
            y_pos = row * img_size

            tk_img = ImageTk.PhotoImage(img)
            self.tk_images.append(tk_img)

            item = self.canvas.create_image(x_pos, y_pos, anchor="nw", image=tk_img)
            self.image_items.append((item, col))

        print(f"ğŸ”² å®Œç¾å¡«å……UI: {self.layout['rows']}x{self.layout['cols']} = {max_displayable}ä¸ªä½ç½®")
        print(f"ğŸ“Š å®é™…å›¾ç‰‡æ•°: {len(self.loaded_images)} | æ˜¾ç¤ºå›¾ç‰‡æ•°: {len(display_images)}")

    def scroll(self):
        """ä¼˜åŒ–çš„æ»šåŠ¨ - æ¯åˆ—é¦–å°¾ç›¸è¿ï¼Œæ— é»‘è‰²åŒºåŸŸ"""
        if not self.image_items or not self.scroll_active:
            self.after(30, self.scroll)
            return

        img_size, _ = self.get_image_size()

        # æŒ‰åˆ—åˆ†ç»„
        by_column = {}
        for item, col_idx in self.image_items:
            if col_idx not in by_column:
                by_column[col_idx] = []
            by_column[col_idx].append(item)

        # æ¯åˆ—ç‹¬ç«‹æ»šåŠ¨ï¼Œé¦–å°¾ç›¸è¿
        for col_idx, items in by_column.items():
            if not items:
                continue

            # æ‰€æœ‰å›¾ç‰‡å‘ä¸‹ç§»åŠ¨
            for item in items:
                self.canvas.move(item, 0, self.scroll_speed)

            # æ£€æŸ¥æ˜¯å¦éœ€è¦å¾ªç¯ - å…³é”®æ”¹è¿›
            for item in items:
                x, y = self.canvas.coords(item)

                if y >= self.current_height:  # å®Œå…¨ç§»å‡ºåº•éƒ¨
                    # æ‰¾åˆ°è¯¥åˆ—æœ€é¡¶éƒ¨çš„ä½ç½®
                    min_y = min(self.canvas.coords(i)[1] for i in items if i != item)
                    new_y = min_y - img_size  # ç´§è´´é¡¶éƒ¨ï¼Œæ— é—´éš™
                    self.canvas.coords(item, x, new_y)

        self.after(30, self.scroll)

    def update_layout(self):
        """æ ¹æ®å®é™…å›¾ç‰‡æ•°é‡æ›´æ–°å¸ƒå±€"""
        if not self.manual_layout:  # åªåœ¨éæ‰‹åŠ¨æ¨¡å¼ä¸‹è‡ªåŠ¨è®¡ç®—å¸ƒå±€
            actual_image_count = len(self.loaded_images)

            # å¦‚æœæ²¡æœ‰å›¾ç‰‡ï¼Œä½¿ç”¨1x1å¸ƒå±€
            if actual_image_count == 0:
                self.layout = {"rows": 1, "cols": 1}
            else:
                # æ ¹æ®å®é™…å›¾ç‰‡æ•°é‡è®¡ç®—æœ€ä½³å¸ƒå±€
                self.layout = self.calculate_optimal_layout(actual_image_count)

        self.update_scroll_directions()

        actual_count = len(self.loaded_images)
        print(f"ğŸ“ å¸ƒå±€: {self.layout['rows']}x{self.layout['cols']} (å®é™…å›¾ç‰‡: {actual_count} å¼ )")
        if self.manual_layout:
            print("ğŸ›ï¸ æ‰‹åŠ¨å¸ƒå±€æ¨¡å¼")
        else:
            print("ğŸ”„ è‡ªåŠ¨å¸ƒå±€æ¨¡å¼ - åŸºäºå®é™…å›¾ç‰‡æ•°é‡")

    def load_images(self):
        """ä¼˜åŒ–çš„å›¾åƒåŠ è½½æ–¹æ³• - åŠ è½½æ‰€æœ‰å›¾åƒ"""
        supported_ext = (".png", ".jpg", ".jpeg", ".gif", ".bmp")
        self.loaded_images.clear()
        self.image_filenames = []

        # è·å–å›¾åƒæ–‡ä»¶åˆ—è¡¨
        image_files = []
        for filename in os.listdir(self.folder):
            if filename.lower().endswith(supported_ext):
                image_files.append(filename)

        # æŒ‰æ–‡ä»¶ä¿®æ”¹æ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
        image_files.sort(key=lambda x: os.path.getmtime(os.path.join(self.folder, x)), reverse=True)

        # åŠ è½½æ‰€æœ‰å›¾åƒï¼ˆç§»é™¤æ•°é‡é™åˆ¶ï¼‰
        for filename in image_files:  # â† ç§»é™¤ [:self.max_visible_images]
            path = os.path.join(self.folder, filename)
            try:
                if filename in self.image_cache:
                    img = self.image_cache[filename]
                else:
                    img = Image.open(path).convert("RGB")
                    self.image_cache[filename] = img

                self.loaded_images.append(img)
                self.image_filenames.append(filename)
            except Exception as e:
                print(f"æ— æ³•åŠ è½½å›¾åƒ {filename}: {e}")

        if not self.loaded_images:
            img = Image.new("RGB", (self.current_width, self.current_height), "black")
            self.loaded_images.append(img)
            self.image_filenames.append("default_black.png")

        print(f"âœ… å·²åŠ è½½ {len(self.loaded_images)} å¼ å®é™…å›¾åƒ")  # â† ä¿®æ”¹è¾“å‡ºä¿¡æ¯

    def get_image_keyword(self, filename):
        """ä¸ä½¿ç”¨å›¾åƒæ˜ å°„ï¼Œç»Ÿä¸€æ ‡ç­¾"""
        return "ComfyUI ç”Ÿæˆå›¾åƒ"

    def __del__(self):
        """ç¡®ä¿ç¨‹åºé€€å‡ºæ—¶è§‚å¯Ÿè€…çº¿ç¨‹åœæ­¢"""
        try:
            if hasattr(self, 'observer') and self.observer:
                self.observer.stop()
                self.observer.join()
        except Exception as e:
            print(f"âŒ åœæ­¢å›¾åƒè§‚å¯Ÿè€…æ—¶å‡ºé”™: {e}")


def create_content_filter():
    """åˆ›å»ºå†…å®¹è¿‡æ»¤è´Ÿå‘æç¤ºè¯"""
    # åŸºç¡€è´¨é‡è¿‡æ»¤
    quality_filters = [
        "low quality", "blurry", "distorted", "unrealistic", "bad anatomy",
        "poor quality", "low resolution", "pixelated", "artifacts"
    ]

    # å†…å®¹å®‰å…¨è¿‡æ»¤
    content_filters = [
        "inappropriate content", "adult content", "explicit content",
        "mature content", "nsfw", "disturbing content", "harmful content",
        "violence", "gore", "weapon", "blood", "injury"
    ]

    # åˆå¹¶æ‰€æœ‰è¿‡æ»¤è¯
    all_filters = quality_filters + content_filters
    return ", ".join(all_filters)


def create_workflow_json(positive_prompt):
    """ç”ŸæˆComfyUIå·¥ä½œæµJSONï¼ŒåŒ…å«å†…å®¹è¿‡æ»¤"""
    global knob_system

    # è·å–åŠ¨æ€è´Ÿå‘æç¤ºè¯
    negative_prompt = create_content_filter()


    # ... å…¶ä»–ä»£ç ä¿æŒä¸å˜ ...

def create_workflow_json(positive_prompt):
    """ç”ŸæˆComfyUIå·¥ä½œæµJSONï¼Œæ ¹æ®æ—‹é’®è§’åº¦åŠ¨æ€è°ƒæ•´åˆ†è¾¨ç‡"""
    global knob_system

    # æ ¹æ®æ—‹é’®å½“å‰è§’åº¦é€‰æ‹©åˆ†è¾¨ç‡
    if hasattr(knob_system, 'current_angle'):
        resolution_info = knob_system.get_resolution_by_angle(knob_system.current_angle)
        selected_width = resolution_info["width"]
        selected_height = resolution_info["height"]
        resolution_mode = resolution_info["mode"]
        print(
            f"ğŸ›ï¸ æ—‹é’®è§’åº¦: {knob_system.current_angle}Â° â†’ åˆ†è¾¨ç‡: {selected_width}Ã—{selected_height} ({resolution_mode})")
    else:
        # é»˜è®¤ä¸­ç­‰åˆ†è¾¨ç‡
        selected_width = 444
        selected_height = 444
        resolution_mode = "medium"
        print(f"ğŸ–¼ï¸ ä½¿ç”¨é»˜è®¤åˆ†è¾¨ç‡: {selected_width}Ã—{selected_height}")

    # æ ¹æ®åˆ†è¾¨ç‡è°ƒæ•´ç”Ÿæˆå‚æ•°
    if resolution_mode == "low":
        steps = 15  # ä½åˆ†è¾¨ç‡å¿«é€Ÿç”Ÿæˆ
        cfg = 6
    elif resolution_mode == "medium":
        steps = 20  # ä¸­ç­‰åˆ†è¾¨ç‡å¹³è¡¡
        cfg = 7
    else:  # high - 1080Ã—1080é«˜åˆ†è¾¨ç‡
        steps = 30  # é«˜åˆ†è¾¨ç‡éœ€è¦æ›´å¤šæ­¥æ•°
        cfg = 9

    workflow = {
        "10": {
            "inputs": {
                "ckpt_name": "lustermix_v15Safetensor.safetensors"
            },
            "class_type": "CheckpointLoaderSimple",
            "_meta": {"title": "Checkpoint Loader"}
        },
        "12": {
            "inputs": {
                "seed": random.randint(1, 2 ** 32),
                "steps": steps,
                "cfg": cfg,
                "sampler_name": "dpmpp_2m",
                "scheduler": "karras",
                "denoise": 1,
                "model": ["10", 0],
                "positive": ["13", 0],
                "negative": ["14", 0],
                "latent_image": ["16", 0]
            },
            "class_type": "KSampler",
            "_meta": {"title": "KSampler"}
        },
        "13": {
            "inputs": {
                "text": positive_prompt,
                "clip": ["10", 1]
            },
            "class_type": "CLIPTextEncode",
            "_meta": {"title": "CLIP Text Encode"}
        },
         "14": {
        "inputs": {
            "text": negative_prompt,  # ä½¿ç”¨åŠ¨æ€ç”Ÿæˆçš„è´Ÿå‘æç¤ºè¯
            "clip": ["10", 1]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {"title": "CLIP Text Encode (Negative)"}
    },
        "15": {
            "inputs": {
                "samples": ["12", 0],
                "vae": ["10", 2]
            },
            "class_type": "VAEDecode",
            "_meta": {"title": "VAE Decode"}
        },
        "16": {
            "inputs": {
                "width": selected_width,
                "height": selected_height,
                "batch_size": 1
            },
            "class_type": "EmptyLatentImage",
            "_meta": {"title": "Empty Latent Image"}
        },
        "17": {
            "inputs": {
                "filename_prefix": f"ComfyUI_{resolution_mode}_{knob_system.current_angle if hasattr(knob_system, 'current_angle') else 0}deg",
                "images": ["15", 0]
            },
            "class_type": "SaveImage",
            "_meta": {"title": "Save Image"}
        }
    }

    return workflow


def check_comfyui_connection():
    """æ£€æŸ¥ComfyUIæœåŠ¡æ˜¯å¦è¿è¡Œ"""
    try:
        session = create_requests_session()
        response = session.get("http://127.0.0.1:8188/system_stats", timeout=3)
        return response.status_code == 200
    except:
        return False


def generate_image_with_comfyui(prompt_text):
    """Generate image using ComfyUI with optimized settings"""
    print(f"ğŸ–¼ï¸ å¼€å§‹å›¾åƒç”Ÿæˆï¼Œæç¤ºè¯: {prompt_text}")

    # æ£€æŸ¥ComfyUIè¿æ¥
    if not check_comfyui_connection():
        print("âŒ ComfyUIæœåŠ¡æœªè¿è¡Œ!")
        print("ğŸ“‹ è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤å¯åŠ¨ComfyUI:")
        print(f"   1. æ‰“å¼€å‘½ä»¤è¡Œçª—å£")
        print(f"   2. è¿›å…¥ç›®å½•: cd C:\\111\\ComfyUI-aki\\ComfyUI-aki-v1.6\\ComfyUI")
        print(f"   3. è¿è¡Œ: python main.py")
        print(f"   4. ç­‰å¾…çœ‹åˆ° 'Starting server' ä¿¡æ¯")
        print(f"   5. ç„¶åé‡æ–°æµ‹è¯•è¯­éŸ³è¯†åˆ«")
        return None

    api_url = "http://127.0.0.1:8188/prompt"

    try:
        session = create_requests_session()
        api_data = {
            "prompt": create_workflow_json(prompt_text),
            "client_id": f"voice_to_comfyui_{int(time.time())}"
        }

        response = session.post(api_url, json=api_data, timeout=15)
        if response.status_code != 200:
            print(f"âŒ APIå“åº”é”™è¯¯: {response.text}")
            return None

        response_data = response.json()
        prompt_id = response_data.get("prompt_id")
        if not prompt_id:
            print("âš ï¸ å“åº”ä¸­æ²¡æœ‰prompt_id")
            return None

        print(f"âœ… æäº¤çš„prompt ID: {prompt_id}")

        # ç­‰å¾…å®Œæˆï¼Œå‡å°‘ç­‰å¾…æ—¶é—´
        for i in range(20):  # å‡å°‘ç­‰å¾…å¾ªç¯æ¬¡æ•°
            time.sleep(2)
            try:
                history_response = session.get("http://127.0.0.1:8188/history", timeout=5)
                history_data = history_response.json()

                if prompt_id in history_data:
                    status = history_data[prompt_id].get("status", {})
                    if status.get("completed", False):
                        print("âœ… å›¾åƒç”Ÿæˆå®Œæˆ!")
                        break
                    elif status.get("error"):
                        print(f"âŒ ä»»åŠ¡å¤±è´¥: {status.get('error')}")
                        return None
            except Exception as e:
                print(f"âš ï¸ æ£€æŸ¥çŠ¶æ€æ—¶å‡ºé”™: {e}")
                continue

        # è·å–ç”Ÿæˆçš„æ–‡ä»¶
        try:
            history_response = session.get("http://127.0.0.1:8188/history", timeout=5)
            history_data = history_response.json()
            outputs = history_data.get(prompt_id, {}).get("outputs", {})

            if "17" in outputs:
                image_files = outputs["17"].get("images", [])
                if image_files:
                    for img in image_files:
                        filename = img["filename"]
                        subfolder = img.get("subfolder", "")

                        if subfolder:
                            image_path = os.path.join(IMAGE_OUTPUT_DIR, subfolder, filename)
                        else:
                            image_path = os.path.join(IMAGE_OUTPUT_DIR, filename)

                        if os.path.exists(image_path):
                            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                            new_filename = f"VoiceGen_{timestamp}_{filename}"
                            destination = os.path.join(IMAGE_OUTPUT_DIR, new_filename)

                            if image_path != destination:
                                shutil.copy2(image_path, destination)

                            print(f"âœ… å›¾åƒå·²ç”Ÿæˆ: {destination}")
                            return destination
                        else:
                            root_path = os.path.join(IMAGE_OUTPUT_DIR, filename)
                            if os.path.exists(root_path):
                                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                                new_filename = f"VoiceGen_{timestamp}_{filename}"
                                destination = os.path.join(IMAGE_OUTPUT_DIR, new_filename)
                                shutil.copy2(root_path, destination)
                                print(f"âœ… å›¾åƒå·²ç”Ÿæˆ: {destination}")
                                return destination
        except Exception as e:
            print(f"âŒ è·å–ç”Ÿæˆå›¾åƒæ—¶å‡ºé”™: {e}")

        print("âš ï¸ æœªæ‰¾åˆ°ç”Ÿæˆçš„å›¾åƒæ–‡ä»¶")
        return None

    except Exception as e:
        print(f"âŒ å›¾åƒç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        return None


def generate_3d_model(image_path):
    """Generate 3D model from image using Tripo API with member optimization"""
    print(f"ğŸ§Š å¼€å§‹3Dæ¨¡å‹ç”Ÿæˆ: {image_path}")

    # æ ¹æ®æ—‹é’®è§’åº¦æ™ºèƒ½é€‰æ‹©æ¨¡å‹ç‰ˆæœ¬
    current_angle = getattr(knob_system, 'current_angle', 0)

    # ä¼šå‘˜ç”¨æˆ·ä½¿ç”¨æ›´å¥½çš„æ¨¡å‹é€‰æ‹©ç­–ç•¥
    if TRIPO_MEMBER_CONFIG["is_member"]:
        if current_angle == 0:  # 1080Ã—1080é«˜åˆ†è¾¨ç‡
            model_version = "v2.0"  # é«˜åˆ†è¾¨ç‡ç”¨v2.0
        else:
            model_version = "v2.0"  # ä¼šå‘˜å…¨éƒ¨ç”¨v2.0ï¼Œäº«å—è´¨é‡ä¼˜åŠ¿
    else:
        model_version = "v1.4"  # å…è´¹ç”¨æˆ·ç”¨v1.4ä¿è¯é€Ÿåº¦

    # æ˜¾ç¤ºé¢„æœŸæ—¶é—´
    time_info = get_expected_generation_time(
        model_version=model_version,
        is_member=TRIPO_MEMBER_CONFIG["is_member"]
    )

    print(f"ğŸ¯ ä½¿ç”¨æ¨¡å‹: {model_version} {'ğŸ‘‘ ä¼šå‘˜ä¸“äº«' if TRIPO_MEMBER_CONFIG['is_member'] else ''}")
    print(f"â±ï¸ å…è´¹ç”¨æˆ·é¢„æœŸ: {time_info['free_user']}")
    print(f"ğŸ‘‘ ä¼šå‘˜ç”¨æˆ·é¢„æœŸ: {time_info['member']}")
    print(f"ğŸš€ é€Ÿåº¦æå‡: {time_info['improvement']}")
    print(f"ğŸ”§ é…ç½®: 1000ä¸ªé¢ | æ ‡å‡†çº¹ç†")

    try:
        if not os.path.exists(image_path):
            print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            return None

        # ä½¿ç”¨ä¼šå‘˜ä¼˜åŒ–çš„ä¼šè¯
        session = create_member_optimized_session()
        headers = {"Authorization": f"Bearer {TRIPO_API_KEY}"}

        # å¦‚æœæ˜¯ä¼šå‘˜ï¼Œæ·»åŠ ä¼˜å…ˆçº§å¤´éƒ¨
        if TRIPO_MEMBER_CONFIG["is_member"]:
            headers.update({
                "X-Priority": "high",
                "X-Member-Tier": "premium"
            })

        # æ­¥éª¤1: ä¸Šä¼ å›¾åƒæ–‡ä»¶
        upload_url = f"{TRIPO_BASE_URL}/upload"

        with open(image_path, "rb") as f:
            files = {"file": ("image.png", f, "image/png")}
            status_msg = "ğŸ“¤ ä¸Šä¼ å›¾åƒæ–‡ä»¶ (ä¼šå‘˜ä¼˜å…ˆé€šé“)..." if TRIPO_MEMBER_CONFIG["is_member"] else "ğŸ“¤ ä¸Šä¼ å›¾åƒæ–‡ä»¶..."
            print(status_msg)
            upload_response = session.post(upload_url, headers=headers, files=files, timeout=30)

        if upload_response.status_code != 200:
            print(f"âŒ å›¾åƒä¸Šä¼ å¤±è´¥: {upload_response.status_code}")
            print(f"å“åº”å†…å®¹: {upload_response.text}")
            return None

        upload_data = upload_response.json()

        # ä»ä¸Šä¼ å“åº”ä¸­è·å–æ–‡ä»¶Token
        file_token = None
        if "data" in upload_data:
            file_token = upload_data["data"].get("image_token") or upload_data["data"].get("token")
        elif "image_token" in upload_data:
            file_token = upload_data["image_token"]
        elif "token" in upload_data:
            file_token = upload_data["token"]

        if not file_token:
            print("âŒ ä¸Šä¼ å“åº”ä¸­æ²¡æœ‰æ‰¾åˆ°æ–‡ä»¶token")
            print(f"å®Œæ•´ä¸Šä¼ å“åº”: {upload_data}")
            return None

        print(f"âœ… å›¾åƒä¸Šä¼ æˆåŠŸï¼ŒToken: {file_token}")

        # æ­¥éª¤2: åˆ›å»ºä»»åŠ¡ - ä½¿ç”¨é€‰å®šçš„æ¨¡å‹ç‰ˆæœ¬å’Œä¼šå‘˜ä¼˜åŒ–
        task_url = f"{TRIPO_BASE_URL}/task"

        task_data = {
            "type": "image_to_model",
            "file": {"type": "png", "file_token": file_token},
            "model_version": model_version,
            "face_limit": 1000,
            "texture_resolution": "standard",
            "quality": "high" if model_version == "v2.0" else "balanced"
        }

        # ä¼šå‘˜ä¸“å±ä¼˜åŒ–å‚æ•°
        if TRIPO_MEMBER_CONFIG["is_member"]:
            task_data.update({
                "priority": "high",  # é«˜ä¼˜å…ˆçº§
                "gpu_tier": "premium",  # é«˜çº§GPU
                "processing_mode": "accelerated"  # åŠ é€Ÿæ¨¡å¼
            })

        task_status = f"({model_version}, ä¼šå‘˜åŠ é€Ÿæ¨¡å¼)" if TRIPO_MEMBER_CONFIG["is_member"] else f"({model_version})"
        print(f"ğŸš€ åˆ›å»º3Dæ¨¡å‹ä»»åŠ¡ {task_status}...")

        task_response = session.post(task_url, headers=headers, json=task_data, timeout=30)

        if task_response.status_code != 200:
            print(f"âŒ åˆ›å»º3Dæ¨¡å‹ä»»åŠ¡å¤±è´¥: {task_response.status_code}")
            print(f"å“åº”å†…å®¹: {task_response.text}")

            # å¦‚æœä¼šå‘˜å‚æ•°ä¸è¢«æ”¯æŒï¼Œå°è¯•ç®€åŒ–ç‰ˆæœ¬
            print("ğŸ”„ å°è¯•ä½¿ç”¨ç®€åŒ–å‚æ•°...")
            fallback_task_data = {
                "type": "image_to_model",
                "file": {"type": "png", "file_token": file_token},
                "model_version": model_version,
                "face_limit": 1000,
                "texture_resolution": "1024"
            }

            task_response = session.post(task_url, headers=headers, json=fallback_task_data, timeout=30)

            if task_response.status_code != 200:
                print(f"âŒ ç®€åŒ–å‚æ•°ä»»åŠ¡ä¹Ÿå¤±è´¥: {task_response.status_code}")
                return None
            else:
                print("âœ… ä½¿ç”¨ç®€åŒ–å‚æ•°åˆ›å»ºä»»åŠ¡æˆåŠŸ")

        task_result = task_response.json()

        # æå–ä»»åŠ¡ID
        task_id = None
        if "data" in task_result:
            task_id = task_result["data"].get("task_id")
        elif "task_id" in task_result:
            task_id = task_result["task_id"]

        if not task_id:
            print("âŒ ä»»åŠ¡å“åº”ä¸­æ²¡æœ‰ä»»åŠ¡ID")
            print(f"å®Œæ•´ä»»åŠ¡å“åº”: {task_result}")
            return None

        print(f"âœ… 3Dæ¨¡å‹ä»»åŠ¡å·²åˆ›å»ºï¼ŒID: {task_id}")

        # æ­¥éª¤3: ç­‰å¾…å®Œæˆ - ä¼šå‘˜ä¼˜åŒ–çš„è½®è¯¢ç­–ç•¥
        max_attempts = 60 if TRIPO_MEMBER_CONFIG["is_member"] else 40
        check_interval = 4 if TRIPO_MEMBER_CONFIG["is_member"] else 6  # ä¼šå‘˜æ›´é¢‘ç¹æ£€æŸ¥

        status_url = f"{TRIPO_BASE_URL}/task/{task_id}"
        start_time = time.time()

        for attempt in range(max_attempts):
            time.sleep(check_interval)
            elapsed_time = int(time.time() - start_time)

            member_status = "ğŸ‘‘ä¼šå‘˜åŠ é€Ÿ" if TRIPO_MEMBER_CONFIG["is_member"] else ""
            print(f"ğŸ“¡ æ£€æŸ¥ä»»åŠ¡çŠ¶æ€... ({attempt + 1}/{max_attempts}) "
                  f"[{model_version}{member_status}] å·²ç”¨æ—¶: {elapsed_time}ç§’")

            try:
                status_response = session.get(status_url, headers=headers, timeout=10)
                if status_response.status_code != 200:
                    print(f"âš ï¸ æ£€æŸ¥çŠ¶æ€å¤±è´¥: {status_response.status_code}")
                    continue

                status_data = status_response.json()

                # æå–çŠ¶æ€
                status = None
                result_data = None

                if "data" in status_data:
                    status = status_data["data"].get("status")
                    result_data = status_data["data"].get("result")
                elif "status" in status_data:
                    status = status_data["status"]
                    result_data = status_data.get("result")

                print(f"ğŸ“Š ä»»åŠ¡çŠ¶æ€: {status}")

                if status == "success" or status == "completed":
                    # æå–æ¨¡å‹URL
                    model_url = None
                    if result_data:
                        if isinstance(result_data, dict):
                            if "pbr_model" in result_data:
                                pbr_model = result_data["pbr_model"]
                                if isinstance(pbr_model, dict) and "url" in pbr_model:
                                    model_url = pbr_model["url"]
                                elif isinstance(pbr_model, str):
                                    model_url = pbr_model

                        # å…œåº•ï¼šä»æ—§å°è¯•æ—§å­—æ®µ
                        if not model_url:
                            model_url = (result_data.get("model") or
                                         result_data.get("model_url") or
                                         result_data.get("output_url") or
                                         result_data.get("glb_url") or
                                         result_data.get("file_url"))

                        # å¦‚æœresult_dataæ˜¯å­—ç¬¦ä¸²URL
                        if isinstance(result_data, str) and result_data.startswith("http"):
                            model_url = result_data

                    if not model_url:
                        print("âŒ å®Œæˆçš„ä»»åŠ¡ä¸­æ²¡æœ‰æ¨¡å‹URL")
                        print(f"å®Œæ•´çŠ¶æ€å“åº”: {status_data}")
                        return None

                    # ä¸‹è½½æ¨¡å‹
                    total_time = int(time.time() - start_time)
                    member_tag = " ğŸ‘‘ä¼šå‘˜åŠ é€Ÿ" if TRIPO_MEMBER_CONFIG["is_member"] else ""
                    print(f"ğŸ“¥ ä¸‹è½½3Dæ¨¡å‹ ({model_version}, 1000é¢): {model_url}")
                    print(f"â±ï¸ æ€»ç”Ÿæˆæ—¶é—´: {total_time}ç§’{member_tag}")

                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

                    # è®¾ç½®è¾“å‡ºç›®å½•å’Œæ–‡ä»¶åæ ¹æ®æ—‹é’®è§’åº¦
                    member_suffix = "_member" if TRIPO_MEMBER_CONFIG["is_member"] else ""

                    if hasattr(knob_system, 'current_angle'):
                        angle = knob_system.current_angle
                        if 0 <= angle < 90:
                            target_dir = r"D:\æ¡Œé¢\bishe01"
                            filename = f"bishe01_{model_version}{member_suffix}_{timestamp}.glb"
                        elif 90 <= angle < 180:
                            target_dir = r"D:\æ¡Œé¢\bishe02"
                            filename = f"bishe02_{model_version}{member_suffix}_{timestamp}.glb"
                        else:
                            target_dir = r"D:\æ¡Œé¢\bishe03"
                            filename = f"bishe03_{model_version}{member_suffix}_{timestamp}.glb"
                    else:
                        target_dir = MODEL_OUTPUT_DIR
                        filename = f"VoiceGen_3D_{model_version}{member_suffix}_{timestamp}.glb"

                    # åˆ›å»ºç›®æ ‡ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                    os.makedirs(target_dir, exist_ok=True)

                    # æ‹¼æ¥å®Œæ•´è¾“å‡ºè·¯å¾„
                    output_file = os.path.join(target_dir, filename)

                    model_response = session.get(model_url, timeout=60)
                    if model_response.status_code == 200:
                        with open(output_file, "wb") as f:
                            f.write(model_response.content)

                        print(f"âœ… 3Dæ¨¡å‹å·²ä¿å­˜åˆ°: {output_file}")
                        print(f"ğŸ¯ æ¨¡å‹è§„æ ¼: {model_version}ç‰ˆæœ¬, 1000ä¸ªé¢, æ ‡å‡†çº¹ç†")
                        if TRIPO_MEMBER_CONFIG["is_member"]:
                            print(f"ğŸ‘‘ ä¼šå‘˜æ€»æ—¶é—´: {total_time}ç§’ (é¢„ä¼°: {time_info['member']})")
                        return output_file
                    else:
                        print(f"âŒ ä¸‹è½½æ¨¡å‹å¤±è´¥: {model_response.status_code}")
                        return None

                elif status == "failed" or status == "error":
                    error_msg = "æœªçŸ¥é”™è¯¯"
                    if "data" in status_data:
                        error_msg = status_data["data"].get("error", error_msg)
                    elif "error" in status_data:
                        error_msg = status_data["error"]
                    print(f"âŒ 3Dæ¨¡å‹ç”Ÿæˆå¤±è´¥: {error_msg}")
                    return None
                else:
                    # ä»»åŠ¡ä»åœ¨è¿›è¡Œä¸­
                    progress = 0
                    if "data" in status_data:
                        progress = status_data["data"].get("progress", 0)
                    elif "progress" in status_data:
                        progress = status_data["progress"]
                    if progress > 0:
                        member_tag = " ğŸ‘‘ä¼šå‘˜åŠ é€Ÿ" if TRIPO_MEMBER_CONFIG["is_member"] else ""
                        print(f"â³ {model_version}æ¨¡å‹ç”Ÿæˆè¿›åº¦: {progress}%{member_tag}")

            except Exception as e:
                print(f"âš ï¸ æ£€æŸ¥çŠ¶æ€æ—¶å‡ºé”™: {e}")
                continue

        print("âŒ 3Dæ¨¡å‹ç”Ÿæˆè¶…æ—¶")
        return None

    except Exception as e:
        print(f"âŒ 3Dæ¨¡å‹ç”Ÿæˆå‡ºé”™: {str(e)}")
        traceback.print_exc()
        return None

        print(f"âœ… 3Dæ¨¡å‹ä»»åŠ¡å·²åˆ›å»ºï¼ŒID: {task_id}")

        # æ­¥éª¤3: è½®è¯¢ä»»åŠ¡çŠ¶æ€
        status_url = f"{TRIPO_BASE_URL}/task/{task_id}"
        max_attempts = 40  # å¢åŠ ç­‰å¾…æ—¶é—´ï¼Œå› ä¸º1000é¢çš„æ¨¡å‹å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´

        for attempt in range(max_attempts):
            time.sleep(6)  # ç¨å¾®å¢åŠ æ£€æŸ¥é—´éš”
            print(f"ğŸ“¡ æ£€æŸ¥ä»»åŠ¡çŠ¶æ€... ({attempt + 1}/{max_attempts}) [v1.4æ¨¡å‹ç”Ÿæˆä¸­]")

            try:
                status_response = session.get(status_url, headers=headers, timeout=10)
                if status_response.status_code != 200:
                    print(f"âš ï¸ æ£€æŸ¥çŠ¶æ€å¤±è´¥: {status_response.status_code}")
                    continue

                status_data = status_response.json()

                # æå–çŠ¶æ€
                status = None
                result_data = None

                if "data" in status_data:
                    status = status_data["data"].get("status")
                    result_data = status_data["data"].get("result")
                elif "status" in status_data:
                    status = status_data["status"]
                    result_data = status_data.get("result")

                print(f"ğŸ“Š ä»»åŠ¡çŠ¶æ€: {status}")

                if status == "success" or status == "completed":
                    # æå–æ¨¡å‹URL
                    model_url = None
                    if result_data:
                        if isinstance(result_data, dict):
                            if "pbr_model" in result_data:
                                pbr_model = result_data["pbr_model"]
                                if isinstance(pbr_model, dict) and "url" in pbr_model:
                                    model_url = pbr_model["url"]
                                elif isinstance(pbr_model, str):
                                    model_url = pbr_model

                        # å…œåº•ï¼šä»æ—§å°è¯•æ—§å­—æ®µ
                        if not model_url:
                            model_url = (result_data.get("model") or
                                         result_data.get("model_url") or
                                         result_data.get("output_url") or
                                         result_data.get("glb_url") or
                                         result_data.get("file_url"))

                        # å¦‚æœresult_dataæ˜¯å­—ç¬¦ä¸²URL
                        if isinstance(result_data, str) and result_data.startswith("http"):
                            model_url = result_data

                    if not model_url:
                        print("âŒ å®Œæˆçš„ä»»åŠ¡ä¸­æ²¡æœ‰æ¨¡å‹URL")
                        print(f"å®Œæ•´çŠ¶æ€å“åº”: {status_data}")
                        return None

                    # ä¸‹è½½æ¨¡å‹
                    print(f"ğŸ“¥ ä¸‹è½½3Dæ¨¡å‹ (v1.4æ¨¡å‹, 1000é¢): {model_url}")
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

                    # è®¾ç½®è¾“å‡ºç›®å½•å’Œæ–‡ä»¶åæ ¹æ®æ—‹é’®è§’åº¦
                    if hasattr(knob_system, 'current_angle'):
                        angle = knob_system.current_angle
                        if 0 <= angle < 90:
                            target_dir = r"D:\æ¡Œé¢\bishe01"
                            filename = f"bishe01_v1.4_1000f_{timestamp}.glb"
                        elif 90 <= angle < 180:
                            target_dir = r"D:\æ¡Œé¢\bishe02"
                            filename = f"bishe02_v1.4_1000f_{timestamp}.glb"
                        else:
                            target_dir = r"D:\æ¡Œé¢\bishe03"
                            filename = f"bishe03_v1.4_1000f_{timestamp}.glb"
                    else:
                        target_dir = MODEL_OUTPUT_DIR
                        filename = f"VoiceGen_3D_v1.4_1000f_{timestamp}.glb"

                    # åˆ›å»ºç›®æ ‡ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                    os.makedirs(target_dir, exist_ok=True)

                    # æ‹¼æ¥å®Œæ•´è¾“å‡ºè·¯å¾„
                    output_file = os.path.join(target_dir, filename)

                    model_response = session.get(model_url, timeout=60)
                    if model_response.status_code == 200:
                        with open(output_file, "wb") as f:
                            f.write(model_response.content)
                        print(f"âœ… 3Dæ¨¡å‹å·²ä¿å­˜åˆ°: {output_file}")
                        print(f"ğŸ¯ æ¨¡å‹è§„æ ¼: v1.4ç‰ˆæœ¬, 1000ä¸ªé¢, æ ‡å‡†çº¹ç†")
                        return output_file
                    else:
                        print(f"âŒ ä¸‹è½½æ¨¡å‹å¤±è´¥: {model_response.status_code}")
                        return None

                elif status == "failed" or status == "error":
                    error_msg = "æœªçŸ¥é”™è¯¯"
                    if "data" in status_data:
                        error_msg = status_data["data"].get("error", error_msg)
                    elif "error" in status_data:
                        error_msg = status_data["error"]
                    print(f"âŒ 3Dæ¨¡å‹ç”Ÿæˆå¤±è´¥: {error_msg}")
                    return None
                else:
                    # ä»»åŠ¡ä»åœ¨è¿›è¡Œä¸­
                    progress = 0
                    if "data" in status_data:
                        progress = status_data["data"].get("progress", 0)
                    elif "progress" in status_data:
                        progress = status_data["progress"]
                    if progress > 0:
                        print(f"â³ v1.4æ¨¡å‹ç”Ÿæˆè¿›åº¦: {progress}% (ç›®æ ‡: 1000é¢)")

            except Exception as e:
                print(f"âš ï¸ æ£€æŸ¥çŠ¶æ€æ—¶å‡ºé”™: {e}")
                continue

        print("âŒ 3Dæ¨¡å‹ç”Ÿæˆè¶…æ—¶")
        return None

    except Exception as e:
        print(f"âŒ 3Dæ¨¡å‹ç”Ÿæˆå‡ºé”™: {str(e)}")
        traceback.print_exc()
        return None


# ========== Arduinoç¡¬ä»¶ç›‘å¬åŠŸèƒ½ ==========
def detect_arduino_port():
    """è‡ªåŠ¨æ£€æµ‹Arduinoç«¯å£ - ä¼˜å…ˆä½¿ç”¨COM9"""
    try:
        ports = serial.tools.list_ports.comports()

        # ä¼˜å…ˆæ£€æŸ¥COM9ï¼ˆArduino Leonardoï¼‰
        for port in ports:
            if port.device == 'COM9':
                print(f"âœ… æ‰¾åˆ°Arduino Leonardoç«¯å£: {port.device}")
                return port.device

        # æŸ¥æ‰¾å…¶ä»–Arduinoç«¯å£
        for port in ports:
            if "Arduino" in port.description or "Leonardo" in port.description or "CH340" in port.description or "USB" in port.description:
                return port.device

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œè¿”å›å¸¸è§ç«¯å£ï¼ˆCOM9ä¼˜å…ˆï¼‰
        common_ports = ['COM9', 'COM3', 'COM4', 'COM5', '/dev/ttyUSB0', '/dev/ttyACM0']
        for port_name in common_ports:
            for port in ports:
                if port.device == port_name:
                    return port_name

        # è¿”å›ç¬¬ä¸€ä¸ªå¯ç”¨ç«¯å£
        if ports:
            return ports[0].device

    except Exception as e:
        print(f"âŒ ç«¯å£æ£€æµ‹å¤±è´¥: {e}")

    return 'COM9'  # é»˜è®¤ç«¯å£æ”¹ä¸ºCOM9


# ========== Main Application ==========
if __name__ == "__main__":
    try:
        print("=" * 60)
        print("ğŸš€ å¯åŠ¨ä¼˜åŒ–ç‰ˆå®æ—¶è¯­éŸ³è¯†åˆ«å›¾åƒ3Dç”Ÿæˆç³»ç»Ÿ")
        print("=" * 60)
        print(f"ğŸ“ åŸºç¡€ç›®å½•: {BASE_DIR}")
        print(f"ğŸ“ ComfyUIç›®å½•: {COMFYUI_DIR}")
        print(f"ğŸ“ å›¾åƒè¾“å‡ºç›®å½•: {IMAGE_OUTPUT_DIR}")
        print(f"ğŸ“ 3Dæ¨¡å‹è¾“å‡ºç›®å½•: {MODEL_OUTPUT_DIR}")
        print(f"ğŸ“ è¯­éŸ³æ–‡æœ¬æ–‡ä»¶: {VOICE_TEXT_FILE}")
        print(f"ğŸ“ Voskæ¨¡å‹è·¯å¾„: {VOSK_MODEL_PATH}")
        print("=" * 60)
        print("ğŸ›ï¸ æ—‹é’®æ§åˆ¶åŠŸèƒ½:")
        print("   æ—‹é’®è§’åº¦ 0Â° â†’ bishe01æ¨¡å‹ + 64Ã—64åˆ†è¾¨ç‡")
        print("   æ—‹é’®è§’åº¦ 90Â° â†’ bishe02æ¨¡å‹ + 444Ã—444åˆ†è¾¨ç‡")
        print("   æ—‹é’®è§’åº¦ 180Â° â†’ bishe03æ¨¡å‹ + 1080Ã—1080åˆ†è¾¨ç‡")
        print("   ğŸ”Œ ç›‘å¬Arduino Leonardoç¡¬ä»¶æ—‹é’®è¾“å…¥ (COM9)")
        print("=" * 60)
        print("âš¡ æ€§èƒ½ä¼˜åŒ–åŠŸèƒ½:")
        print(f"   - æ™ºèƒ½åˆ†è¾¨ç‡åˆ‡æ¢: 64Ã—64 / 444Ã—444 / 1080Ã—1080")
        print(f"   - æœ€å¤§æ˜¾ç¤ºå›¾åƒæ•°: {MAX_IMAGES_PER_COLUMN}")
        print(f"   - å›¾åƒåŠ è½½å»¶è¿Ÿ: {IMAGE_LOAD_DELAY}ç§’")
        print(f"   - UIæ›´æ–°é—´éš”: {UI_UPDATE_INTERVAL}æ¯«ç§’")
        print(f"   - Arduino Leonardoæ—‹é’®æ§åˆ¶ComfyUIåˆ†è¾¨ç‡")
        print("=" * 60)

        # åŠ è½½å›¾åƒæ–‡æœ¬æ˜ å°„å…³ç³»
        load_image_mapping()

        # æ£€æŸ¥ComfyUIè¿æ¥
        print("ğŸ” æ£€æŸ¥ComfyUIæœåŠ¡çŠ¶æ€...")
        if check_comfyui_connection():
            print("âœ… ComfyUIæœåŠ¡æ­£åœ¨è¿è¡Œ")
        else:
            print("âš ï¸ ComfyUIæœåŠ¡æœªè¿è¡Œ")
            print("ğŸ“‹ è¯·åœ¨å¦ä¸€ä¸ªå‘½ä»¤è¡Œçª—å£ä¸­å¯åŠ¨ComfyUI:")
            print(f"   cd {COMFYUI_DIR}")
            print("   python main.py")
            print("âš ï¸ æ³¨æ„: å¦‚æœä¸å¯åŠ¨ComfyUIï¼Œè¯­éŸ³è¯†åˆ«ä»å¯å·¥ä½œï¼Œä½†æ— æ³•ç”Ÿæˆå›¾åƒ")
            print("=" * 60)

        # åŠ è½½å›¾åƒæ–‡æœ¬æ˜ å°„å…³ç³»
        load_image_mapping()

        # æ£€æµ‹Arduinoç«¯å£
        print("ğŸ” æ£€æµ‹Arduino Leonardoç¡¬ä»¶ç«¯å£...")
        arduino_port = detect_arduino_port()
        print(f"ğŸ“¡ å°†å°è¯•è¿æ¥ç«¯å£: {arduino_port} (Arduino Leonardo)")

        # æ£€æŸ¥ComfyUIè¿æ¥
        print("ğŸ” æ£€æŸ¥ComfyUIæœåŠ¡çŠ¶æ€...")
        if check_comfyui_connection():
            print("âœ… ComfyUIæœåŠ¡æ­£åœ¨è¿è¡Œ")
        else:
            print("âš ï¸ ComfyUIæœåŠ¡æœªè¿è¡Œ")
            print("ğŸ“‹ è¯·åœ¨å¦ä¸€ä¸ªå‘½ä»¤è¡Œçª—å£ä¸­å¯åŠ¨ComfyUI:")
            print(f"   cd {COMFYUI_DIR}")
            print("   python main.py")
            print("âš ï¸ æ³¨æ„: å¦‚æœä¸å¯åŠ¨ComfyUIï¼Œè¯­éŸ³è¯†åˆ«ä»å¯å·¥ä½œï¼Œä½†æ— æ³•ç”Ÿæˆå›¾åƒ")
            print("=" * 60)

        # åˆ›å»ºæ–‡æœ¬æ˜¾ç¤ºçª—å£ï¼ˆä¸»çª—å£ï¼‰
        text_app = TextDisplayApp(arduino_port)
        # åˆ›å»ºå›¾åƒæ˜¾ç¤ºçª—å£ï¼ˆå­çª—å£ï¼‰
        image_app = DynamicLayoutApp(IMAGE_DISPLAY_FOLDER, text_app)

        # è®¾ç½®ç›¸äº’å¼•ç”¨
        text_app.set_image_app(image_app)

        print("âœ… åŒçª—å£ç•Œé¢å·²å¯åŠ¨")
        print("ğŸ¤ å®æ—¶è¯­éŸ³è¯†åˆ«å°†è‡ªåŠ¨å¼€å§‹...")
        print("ğŸ”„ æ£€æµ‹åˆ°è¯­éŸ³åå°†è‡ªåŠ¨ç”Ÿæˆå›¾åƒå’Œ3Dæ¨¡å‹")
        # æ˜¾ç¤ºä¼šå‘˜çŠ¶æ€
        if TRIPO_MEMBER_CONFIG["is_member"]:
            print("=" * 60)
            print("ğŸ‘‘ Tripo AI ä¼šå‘˜çŠ¶æ€ï¼šå·²æ¿€æ´»")
            print("ğŸš€ äº«æœ‰çš„åŠ é€Ÿç‰¹æƒï¼š")
            print("   âœ… ä¼˜å…ˆé˜Ÿåˆ—å¤„ç† (å‡å°‘30%ç­‰å¾…)")
            print("   âœ… é«˜æ€§èƒ½GPUé›†ç¾¤ (æå‡20%é€Ÿåº¦)")
            print("   âœ… 3ä¸ªå¹¶å‘ä»»åŠ¡æ”¯æŒ")
            print("   âœ… å‡å°‘APIé™æµé™åˆ¶")
            print("ğŸ“Š é¢„æœŸæ€§èƒ½æå‡ï¼š")

            for version in ["v1.4", "v2.0"]:
                time_info = get_expected_generation_time(version, is_member=True)
                print(f"   {version}: {time_info['free_user']} â†’ {time_info['member']} ({time_info['improvement']})")

            print("ğŸ¯ ä¼šå‘˜ç­–ç•¥ï¼šå…¨éƒ¨ä½¿ç”¨v2.0æ¨¡å‹è·å¾—æœ€ä½³è´¨é‡")
            print("=" * 60)
        else:
            print("âš ï¸ æœªå¼€é€šTripo AIä¼šå‘˜ï¼Œä½¿ç”¨æ ‡å‡†é€Ÿåº¦é…ç½®")
        print("ğŸ·ï¸ å›¾åƒä¸Šå°†æ˜¾ç¤ºå¯¹åº”çš„è¯­éŸ³å…³é”®è¯")
        print("ğŸ–¼ï¸ å›¾åƒå°†è‡ªåŠ¨é€‚åº”çª—å£å¤§å°å˜åŒ–")
        print("ğŸ›ï¸ è¯·æ‰‹åŠ¨æ—‹è½¬Arduino Leonardoç¡¬ä»¶æ—‹é’®æ¥æ§åˆ¶åˆ†è¾¨ç‡")
        print("ğŸ“Š æ—‹é’®è§’åº¦å°†å®æ—¶æ§åˆ¶ComfyUIå›¾åƒç”Ÿæˆåˆ†è¾¨ç‡")
        print("âš¡ ç³»ç»Ÿå·²ä¼˜åŒ–æ€§èƒ½ï¼Œé™ä½èµ„æºå ç”¨")
        print("=" * 60)
        print("ğŸš€ ç³»ç»Ÿå¯åŠ¨å®Œæˆï¼Œå¼€å§‹ç›‘å¬è¯­éŸ³è¾“å…¥å’ŒArduino Leonardoæ—‹é’®...")

        # å¯åŠ¨ä¸»å¾ªç¯
        text_app.mainloop()

    except KeyboardInterrupt:
        print("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­ç¨‹åº")
        print("ğŸ”„ æ­£åœ¨æ¸…ç†èµ„æº...")

    except Exception as e:
        print(f"âŒ åº”ç”¨ç¨‹åºé”™è¯¯: {str(e)}")
        traceback.print_exc()

    finally:
        print("ğŸ‘‹ ç¨‹åºå·²é€€å‡º")
        print("ğŸ“Š ä¼šè¯ç»Ÿè®¡:")
        if 'image_text_mapping' in globals():
            print(f"   - æ€»ç”Ÿæˆå›¾åƒ: {len(image_text_mapping)} å¼ ")
        print(f"   - è¿è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 60)
